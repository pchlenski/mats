{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature search\n",
    "\n",
    "We are looking for a feature that has the following properites:\n",
    "* Predicted by presence of a single token with high precision and recall\n",
    "* Minimal number of attention heads contributing to SAE feature\n",
    "\n",
    "This is the plan:\n",
    "* Let `DD := data/processed/gelu_1l_audit`\n",
    "* Compute and store activations, logits, SAE features for all data points\n",
    "    * Store in `DD/activations`\n",
    "* Find (feature, token) pairs:\n",
    "    * Take top K activations for each SAE feature\n",
    "    * Take the top token in the dataset for these examples\n",
    "    * Store in `DD/token_feature_pairs`\n",
    "* Evaluate precision and recall of `FEATURE IF TOKEN` predictor\n",
    "    * Store in `DD/precision_recall.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some hyperparameters\n",
    "\n",
    "MODEL = \"gelu-1l\"\n",
    "RUN = \"run1\"\n",
    "DD = f\"../data/processed/{MODEL}_{RUN}_audit\"\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/envs/sprint/lib/python3.10/site-packages (from scikit-learn) (1.26.2)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/sprint/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m125.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.2 scipy-1.11.4 threadpoolctl-3.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sprint.loading import load_all\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure DD exists\n",
    "\n",
    "if not os.path.exists(DD):\n",
    "    os.mkdir(DD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-1l into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Changing model dtype to torch.float16\n",
      "{'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 2048,\n",
      " 'dict_mult': 8,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'num_tokens': 2000000000,\n",
      " 'seed': 52,\n",
      " 'seq_len': 128}\n"
     ]
    }
   ],
   "source": [
    "# Load model, data, and SAE\n",
    "\n",
    "model, data, sae = load_all(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief detour: how to stash all of our activations conveniently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 48262])\n",
      "dict_keys(['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized'])\n",
      "HookedTransformer(\n",
      "  (embed): Embed()\n",
      "  (hook_embed): HookPoint()\n",
      "  (pos_embed): PosEmbed()\n",
      "  (hook_pos_embed): HookPoint()\n",
      "  (blocks): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (ln1): LayerNormPre(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (ln2): LayerNormPre(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (hook_k): HookPoint()\n",
      "        (hook_q): HookPoint()\n",
      "        (hook_v): HookPoint()\n",
      "        (hook_z): HookPoint()\n",
      "        (hook_attn_scores): HookPoint()\n",
      "        (hook_pattern): HookPoint()\n",
      "        (hook_result): HookPoint()\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (hook_pre): HookPoint()\n",
      "        (hook_post): HookPoint()\n",
      "      )\n",
      "      (hook_attn_in): HookPoint()\n",
      "      (hook_q_input): HookPoint()\n",
      "      (hook_k_input): HookPoint()\n",
      "      (hook_v_input): HookPoint()\n",
      "      (hook_mlp_in): HookPoint()\n",
      "      (hook_attn_out): HookPoint()\n",
      "      (hook_mlp_out): HookPoint()\n",
      "      (hook_resid_pre): HookPoint()\n",
      "      (hook_resid_mid): HookPoint()\n",
      "      (hook_resid_post): HookPoint()\n",
      "    )\n",
      "  )\n",
      "  (ln_final): LayerNormPre(\n",
      "    (hook_scale): HookPoint()\n",
      "    (hook_normalized): HookPoint()\n",
      "  )\n",
      "  (unembed): Unembed()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Brief sanity check: how can we pull out all of the model components for a batch:\n",
    "\n",
    "data_batch = data[:32, :]\n",
    "logits_batch, cache_batch = model.run_with_cache(data_batch)\n",
    "\n",
    "print(logits_batch.shape)\n",
    "print(cache_batch.keys())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.mlp.hook_post\n"
     ]
    }
   ],
   "source": [
    "# Get_act_name is a helper function that returns the name of the activation function\n",
    "\n",
    "from transformer_lens.utils import get_act_name\n",
    "\n",
    "print(get_act_name(\"post\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAE outputs are (loss, x_reconstruct, acts, l2_loss, l1_loss)\n",
    "# We just want the activations\n",
    "\n",
    "sae(cache_batch[\"blocks.0.mlp.hook_post\"])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5de38c6140>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's try to visualize one SAE output - first 512 activations of the first batch element\n",
    "\n",
    "plt.matshow(sae(cache_batch[\"blocks.0.mlp.hook_post\"])[2].detach().cpu().numpy()[0, :, :512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify we can get logits from activations\n",
    "\n",
    "\n",
    "def get_logits(model, cache):\n",
    "    mlp_w = model.state_dict()[\"blocks.0.mlp.W_out\"]\n",
    "    mlp_b = model.state_dict()[\"blocks.0.mlp.b_out\"]\n",
    "    mlp_out = cache[\"blocks.0.mlp.hook_post\"] @ mlp_w + mlp_b\n",
    "    residual = cache[\"blocks.0.hook_resid_mid\"]\n",
    "\n",
    "    return model.unembed(model.ln_final(mlp_out + residual))\n",
    "\n",
    "\n",
    "assert torch.isclose(get_logits(model, cache_batch), logits_batch).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through data, stash values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1683 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1683/1683 [06:14<00:00,  4.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ensure we don't clobber anything\n",
    "# if False:\n",
    "if True:\n",
    "    # First, ensure target paths are empty\n",
    "    # paths = [os.path.join(DD, f) for f in [\"inputs\", \"activations\", \"features\", \"logits\", \"activations_r\"]]\n",
    "    # paths = [os.path.join(DD, f) for f in [\"activations\", \"features\"]]\n",
    "    paths = [os.path.join(DD, f) for f in [\"features\"]]\n",
    "    for path in paths:\n",
    "        if os.path.exists(path):\n",
    "            for f in os.listdir(path):\n",
    "                os.remove(os.path.join(path, f))\n",
    "            os.rmdir(path)\n",
    "        os.mkdir(path)\n",
    "\n",
    "    for i, batch in enumerate(tqdm(data.split(BATCH_SIZE))):\n",
    "        # Run model\n",
    "        logits_batch, cache_batch = model.run_with_cache(\n",
    "            batch,\n",
    "        )\n",
    "\n",
    "        # Get activations\n",
    "        activations_batch = cache_batch[\"blocks.0.mlp.hook_post\"]\n",
    "\n",
    "        # Get SAE features, reconstructed activations, reconstructed logits\n",
    "        _, activations_r_batch, features_batch, _, _ = sae(activations_batch)\n",
    "        features_batch = features_batch.to_sparse()\n",
    "\n",
    "        # Save everything\n",
    "        # for x, path in zip([batch, activations_batch, features_batch, logits_batch, activations_r_batch], paths):\n",
    "        # for x, path in zip([activations_batch, features_batch], paths):\n",
    "        for x, path in zip([features_batch], paths):\n",
    "            torch.save(x, os.path.join(path, f\"{i}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up some memory\n",
    "try:\n",
    "    del batch, cache_batch, activations_batch, features_batch, logits_batch, activations_r_batch\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute per-feature activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 16384, number of files: 1683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [04:56<00:00,  1.06s/it]\n",
      "100%|██████████| 280/280 [04:29<00:00,  1.04it/s]\n",
      "100%|██████████| 280/280 [04:14<00:00,  1.10it/s]\n",
      "100%|██████████| 280/280 [04:31<00:00,  1.03it/s]\n",
      "100%|██████████| 280/280 [04:57<00:00,  1.06s/it]\n",
      "100%|██████████| 280/280 [05:32<00:00,  1.19s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# This is kind of a crazy way to do this, but because of memory constraints I'm just gonna do it...\n",
    "\n",
    "feature_files = os.listdir(os.path.join(DD, \"features\"))\n",
    "feature_dim = torch.load(os.path.join(DD, \"features\", feature_files[0])).shape[-1]\n",
    "n_files = len(feature_files)\n",
    "print(f\"Number of features: {feature_dim}, number of files: {n_files}\")\n",
    "\n",
    "# Split feature_files into chunks, again for memory reasons\n",
    "CHUNKS = 6\n",
    "feature_files = [feature_files[i : i + n_files // CHUNKS] for i in range(0, n_files, n_files // CHUNKS)]\n",
    "\n",
    "# # Create activation_vectors directory\n",
    "# if os.path.exists(os.path.join(DD, \"feature_vectors\")):\n",
    "#     for f in os.listdir(os.path.join(DD, \"feature_vectors\")):\n",
    "#         os.remove(os.path.join(DD, \"feature_vectors\", f))\n",
    "#     os.rmdir(os.path.join(DD, \"feature_vectors\"))\n",
    "# os.mkdir(os.path.join(DD, \"feature_vectors\"))\n",
    "\n",
    "# Accumulate feature vectors in list\n",
    "with torch.no_grad():\n",
    "    for k, files_batch in enumerate(feature_files):\n",
    "        all_features = [[] for _ in range(feature_dim)]\n",
    "        for i, file in enumerate(tqdm(files_batch)):\n",
    "            feature = torch.load(os.path.join(DD, \"features\", file)).to_dense()  # .cpu()\n",
    "            for j in range(feature_dim):\n",
    "                all_features[j].append(feature[:, :, j].to_sparse())\n",
    "\n",
    "        # Basic save\n",
    "        with open(os.path.join(DD, f\"all_features_vectors_{k}.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(all_features, f)\n",
    "\n",
    "        # Save feature vectors individually\n",
    "        for j in range(feature_dim):\n",
    "            torch.save(torch.cat(all_features[j]), os.path.join(DD, \"feature_vectors\", f\"{j}_{k}.pt\"))\n",
    "\n",
    "        # Free up some memory\n",
    "        try:\n",
    "            del all_features\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16384 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [08:33<00:00, 31.89it/s] \n"
     ]
    }
   ],
   "source": [
    "# Merge feature vectors\n",
    "os.mkdir(os.path.join(DD, \"feature_vectors_merged\"))\n",
    "\n",
    "for i in tqdm(range(feature_dim)):\n",
    "    feature_merged = torch.cat(\n",
    "        [torch.load(os.path.join(DD, \"feature_vectors\", f\"{i}_{k}.pt\")) for k in range(CHUNKS + 1)]\n",
    "    )\n",
    "    torch.save(feature_merged, os.path.join(DD, \"feature_vectors_merged\", f\"{i}_full.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([215402, 128])\n",
      "215402\n"
     ]
    }
   ],
   "source": [
    "# Verify that shapes are correct\n",
    "\n",
    "feature_merged = torch.load(os.path.join(DD, \"feature_vectors_merged\", \"0_full.pt\"))\n",
    "print(feature_merged.shape)  # Should be (n_samples, n_tokens)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get (feature, token) pairs; audit for predictive accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16384 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [03:34<00:00, 76.25it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_idx</th>\n",
       "      <th>token_str</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>248</td>\n",
       "      <td>a</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191</td>\n",
       "      <td>\\r</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>\\r</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17371</td>\n",
       "      <td>utf</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191</td>\n",
       "      <td>\\r</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16379</th>\n",
       "      <td>191</td>\n",
       "      <td>\\r</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16380</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16381</th>\n",
       "      <td>286</td>\n",
       "      <td>and</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16382</th>\n",
       "      <td>8461</td>\n",
       "      <td>spr</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16383</th>\n",
       "      <td>191</td>\n",
       "      <td>\\r</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16384 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      token_idx token_str count\n",
       "0           248         a    19\n",
       "1           191        \\r    14\n",
       "2           191        \\r     9\n",
       "3         17371       utf   100\n",
       "4           191        \\r    12\n",
       "...         ...       ...   ...\n",
       "16379       191        \\r    13\n",
       "16380        19         1   100\n",
       "16381       286       and   100\n",
       "16382      8461       spr    59\n",
       "16383       191        \\r     9\n",
       "\n",
       "[16384 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find (activation, feature pairs)\n",
    "\n",
    "# Find the top K activations for each feature\n",
    "# Count tokens in top-K activating examples\n",
    "\n",
    "TOP_K = 100\n",
    "feature_top_tokens = pd.DataFrame(index=range(feature_dim), columns=[\"token_idx\", \"token_str\", \"count\"])\n",
    "\n",
    "for i in tqdm(range(feature_dim)):\n",
    "    # Load feature as an (n_samples, n_tokens) matrix\n",
    "    feature = torch.load(os.path.join(DD, \"feature_vectors_merged\", f\"{i}_full.pt\")).to_dense()\n",
    "\n",
    "    # Get top K activations using a flat view into the feature\n",
    "    feature_flat = feature.view(-1)\n",
    "    topk_vals, indices_flat = torch.topk(feature_flat, TOP_K, largest=True)\n",
    "\n",
    "    # Reshape indices to 2-D\n",
    "    n, m = feature.shape\n",
    "    r, c = indices_flat // m, indices_flat % m\n",
    "    idx = torch.stack([r, c], dim=1)\n",
    "\n",
    "    # What are the tokens?\n",
    "    feature_tokens = data[idx[:, 0], idx[:, 1]]\n",
    "    token_counts = torch.bincount(feature_tokens, minlength=len(model.tokenizer))\n",
    "    top_token = torch.argmax(token_counts).item()\n",
    "\n",
    "    # Save to dataframe\n",
    "    feature_top_tokens.loc[i] = [top_token, model.to_single_str_token(top_token), token_counts[top_token].item()]\n",
    "\n",
    "feature_top_tokens.to_csv(os.path.join(DD, \"feature_top_tokens.csv\"))\n",
    "feature_top_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16384 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [03:51<00:00, 70.88it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_token</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>248</td>\n",
       "      <td>0.129994</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.003281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191</td>\n",
       "      <td>0.031985</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.013569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>0.020802</td>\n",
       "      <td>0.007262</td>\n",
       "      <td>0.010766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17371</td>\n",
       "      <td>0.013031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191</td>\n",
       "      <td>0.031208</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.008434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16379</th>\n",
       "      <td>191</td>\n",
       "      <td>0.022464</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.010001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16380</th>\n",
       "      <td>19</td>\n",
       "      <td>0.662478</td>\n",
       "      <td>0.600608</td>\n",
       "      <td>0.630028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16381</th>\n",
       "      <td>286</td>\n",
       "      <td>0.435758</td>\n",
       "      <td>0.3408</td>\n",
       "      <td>0.382474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16382</th>\n",
       "      <td>8461</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16383</th>\n",
       "      <td>191</td>\n",
       "      <td>0.021246</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.009504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16384 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      top_token precision    recall        f1\n",
       "0           248  0.129994  0.001661  0.003281\n",
       "1           191  0.031985  0.008611  0.013569\n",
       "2           191  0.020802  0.007262  0.010766\n",
       "3         17371  0.013031       1.0  0.025727\n",
       "4           191  0.031208  0.004876  0.008434\n",
       "...         ...       ...       ...       ...\n",
       "16379       191  0.022464  0.006432  0.010001\n",
       "16380        19  0.662478  0.600608  0.630028\n",
       "16381       286  0.435758    0.3408  0.382474\n",
       "16382      8461  0.003102       1.0  0.006184\n",
       "16383       191  0.021246  0.006121  0.009504\n",
       "\n",
       "[16384 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get precision, recall, F1 for naive prediction: top token -> feature fires\n",
    "\n",
    "top_token_audit = pd.DataFrame(index=range(feature_dim), columns=[\"top_token\", \"precision\", \"recall\", \"f1\"])\n",
    "\n",
    "for i in tqdm(range(feature_dim)):\n",
    "    top_token = feature_top_tokens.loc[i, \"token_idx\"]\n",
    "    feature = torch.load(os.path.join(DD, \"feature_vectors_merged\", f\"{i}_full.pt\")).to_dense()\n",
    "\n",
    "    # n_correct = 0\n",
    "    # for j in range(len(data)):\n",
    "    #     for k in range(len(data[j])):\n",
    "    #         if (data[j, k] == top_token and feature[j, k] > 0) or (data[j, k] != top_token and feature[j, k] == 0):\n",
    "    #             n_correct += 1\n",
    "\n",
    "    bool1 = data == top_token\n",
    "    bool2 = feature > 0\n",
    "\n",
    "    # n_correct = ((bool1 & bool2) | (~bool1 & ~bool2)).sum().item()\n",
    "    tp = (bool1 & bool2).sum().item()\n",
    "    fp = (~bool1 & bool2).sum().item()\n",
    "    fn = (bool1 & ~bool2).sum().item()\n",
    "    tn = (~bool1 & ~bool2).sum().item()\n",
    "\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    f1 = 2 * p * r / (p + r)\n",
    "\n",
    "    top_token_audit.loc[i] = [top_token, p, r, f1]\n",
    "\n",
    "top_token_audit.to_csv(os.path.join(DD, \"top_token_audit.csv\"))\n",
    "top_token_audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(feature_top_tokens, top_token_audit, left_index=True, right_index=True).drop(\n",
    "    columns=[\"top_token\"]\n",
    ").sort_values(\"f1\", ascending=False).to_csv(os.path.join(DD, \"top_token_audit_merged.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
