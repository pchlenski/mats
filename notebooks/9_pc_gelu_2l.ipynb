{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Changing model dtype to torch.float16\n",
      "Model device: cuda:0\n",
      "Tokens shape: torch.Size([215402, 128]), dtype: torch.int64, device: cuda:0\n",
      "Loading l1 from HuggingFace at gelu-2l_L1_16384_mlp_out_50\n",
      "{'act_name': 'blocks.1.hook_mlp_out',\n",
      " 'act_size': 512,\n",
      " 'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 512,\n",
      " 'device': 'cuda:0',\n",
      " 'dict_mult': 32,\n",
      " 'dict_size': 16384,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'layer': 1,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'model_name': 'gelu-2l',\n",
      " 'num_tokens': 2000000000,\n",
      " 'remove_rare_dir': False,\n",
      " 'seed': 50,\n",
      " 'seq_len': 128,\n",
      " 'site': 'mlp_out'}\n",
      "Encoder device: cuda:0\n",
      "Loading l0 from HuggingFace at gelu-2l_L0_16384_mlp_out_51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab659614e3a442f98abfa6adc381beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gelu-2l_L0_16384_mlp_out_51_cfg.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'act_name': 'blocks.0.hook_mlp_out',\n",
      " 'act_size': 512,\n",
      " 'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 512,\n",
      " 'device': 'cuda:1',\n",
      " 'dict_mult': 32,\n",
      " 'dict_size': 16384,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'layer': 0,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'model_name': 'gelu-2l',\n",
      " 'num_tokens': 2000000000,\n",
      " 'remove_rare_dir': False,\n",
      " 'seed': 51,\n",
      " 'seq_len': 128,\n",
      " 'site': 'mlp_out'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a12c0db001423e8335289ffddc2354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gelu-2l_L0_16384_mlp_out_51.pt:   0%|          | 0.00/67.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from mats.loading import load_all, load_sae\n",
    "\n",
    "model, data, sae_l1 = load_all(model_name=\"gelu-2l\", run_id=\"l1\")\n",
    "sae_l0 = load_sae(run_id=\"l0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('blocks.1.hook_dsfasdf',)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformer_lens import utils\n",
    "\n",
    "utils.get_act_name(\"dsfasdf\", 1),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that it's two layers\n",
    "len(model.blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 2048])\n",
      "torch.Size([512, 16384])\n"
     ]
    }
   ],
   "source": [
    "# Shapes - gelu-2l\n",
    "\n",
    "print(model.blocks[0].mlp.W_in.shape)\n",
    "print(sae_l1.W_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-1l into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Changing model dtype to torch.float16\n",
      "Model device: cuda:0\n",
      "Tokens shape: torch.Size([215402, 128]), dtype: torch.int64, device: cuda:0\n",
      "Loading run1 from HuggingFace at 25\n",
      "{'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 2048,\n",
      " 'dict_mult': 8,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'num_tokens': 2000000000,\n",
      " 'seed': 52,\n",
      " 'seq_len': 128}\n",
      "Encoder device: cuda:0\n",
      "torch.Size([512, 2048])\n",
      "torch.Size([2048, 16384])\n"
     ]
    }
   ],
   "source": [
    "# That doesn't look right... let's check this for the old model\n",
    "\n",
    "model, data, sae = load_all()\n",
    "\n",
    "print(model.blocks[0].mlp.W_in.shape)\n",
    "print(sae.W_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, got input (1), mat (1x512), vec (2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Verify linearization still works at L0\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinearization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m analyze_linearized_feature\n\u001b[0;32m----> 5\u001b[0m \u001b[43manalyze_linearized_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msae_l0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# batch_size=32,\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlp_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mats/src/mats/linearization.py:137\u001b[0m, in \u001b[0;36manalyze_linearized_feature\u001b[0;34m(feature_idx, sample_idx, token_idx, layer, head, model, encoder, data, n_tokens, mlp_out, use_ln, feature)\u001b[0m\n\u001b[1;32m    135\u001b[0m x_mid \u001b[38;5;241m=\u001b[39m mid_acts[\u001b[38;5;241m0\u001b[39m, token_idx][\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m    136\u001b[0m my_fun \u001b[38;5;241m=\u001b[39m ln2_mlp_until_post \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mlp_out \u001b[38;5;28;01melse\u001b[39;00m ln2_mlp_until_out\n\u001b[0;32m--> 137\u001b[0m feature_mid \u001b[38;5;241m=\u001b[39m \u001b[43mget_tangent_plane_at_point\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_ln\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_ln\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    141\u001b[0m mid_acts_feature_scores \u001b[38;5;241m=\u001b[39m mid_acts\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39md_model) \u001b[38;5;241m@\u001b[39m feature_mid\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Unembed\u001b[39;00m\n",
      "File \u001b[0;32m~/mats/src/mats/linearization.py:17\u001b[0m, in \u001b[0;36mget_tangent_plane_at_point\u001b[0;34m(x_0_new, f, range_normal)\u001b[0m\n\u001b[1;32m     15\u001b[0m x_0_new\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: f(x) \u001b[38;5;241m@\u001b[39m range_normal\n\u001b[0;32m---> 17\u001b[0m grad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(\u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_0_new\u001b[49m\u001b[43m)\u001b[49m, x_0_new)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/mats/src/mats/linearization.py:16\u001b[0m, in \u001b[0;36mget_tangent_plane_at_point.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Linear approximation of f at x_0_new\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m x_0_new\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrange_normal\u001b[49m\n\u001b[1;32m     17\u001b[0m grad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(g(x_0_new), x_0_new)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, got input (1), mat (1x512), vec (2048)"
     ]
    }
   ],
   "source": [
    "# Verify linearization still works at L0\n",
    "\n",
    "from mats.linearization import analyze_linearized_feature\n",
    "\n",
    "analyze_linearized_feature(\n",
    "    feature_idx=100,\n",
    "    sample_idx=30,\n",
    "    token_idx=30,\n",
    "    model=model,\n",
    "    data=data,\n",
    "    encoder=sae_l0,\n",
    "    layer=0,\n",
    "    # batch_size=32,\n",
    "    n_tokens=10,\n",
    "    mlp_out=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "analyze_linearized_feature() got an unexpected keyword argument 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Repeat at L1 (this multiplies by the wrong features, but I'm just seeing what breaks)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43manalyze_linearized_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msae_l1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: analyze_linearized_feature() got an unexpected keyword argument 'batch_size'"
     ]
    }
   ],
   "source": [
    "# Repeat at L1 (this multiplies by the wrong features, but I'm just seeing what breaks)\n",
    "\n",
    "analyze_linearized_feature(\n",
    "    feature_idx=100,\n",
    "    sample_idx=30,\n",
    "    token_idx=30,\n",
    "    model=model,\n",
    "    layer=1,\n",
    "    data=data,\n",
    "    encoder=sae_l1,\n",
    "    batch_size=32,\n",
    "    n_tokens=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Changing model dtype to torch.float16\n",
      "Model device: cuda:0\n",
      "Tokens shape: torch.Size([215402, 128]), dtype: torch.int64, device: cuda:0\n",
      "{'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 2048,\n",
      " 'dict_mult': 8,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'num_tokens': 2000000000,\n",
      " 'seed': 52,\n",
      " 'seq_len': 128}\n",
      "Encoder device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(HookedTransformer(\n",
       "   (embed): Embed()\n",
       "   (hook_embed): HookPoint()\n",
       "   (pos_embed): PosEmbed()\n",
       "   (hook_pos_embed): HookPoint()\n",
       "   (blocks): ModuleList(\n",
       "     (0-1): 2 x TransformerBlock(\n",
       "       (ln1): LayerNormPre(\n",
       "         (hook_scale): HookPoint()\n",
       "         (hook_normalized): HookPoint()\n",
       "       )\n",
       "       (ln2): LayerNormPre(\n",
       "         (hook_scale): HookPoint()\n",
       "         (hook_normalized): HookPoint()\n",
       "       )\n",
       "       (attn): Attention(\n",
       "         (hook_k): HookPoint()\n",
       "         (hook_q): HookPoint()\n",
       "         (hook_v): HookPoint()\n",
       "         (hook_z): HookPoint()\n",
       "         (hook_attn_scores): HookPoint()\n",
       "         (hook_pattern): HookPoint()\n",
       "         (hook_result): HookPoint()\n",
       "       )\n",
       "       (mlp): MLP(\n",
       "         (hook_pre): HookPoint()\n",
       "         (hook_post): HookPoint()\n",
       "       )\n",
       "       (hook_attn_in): HookPoint()\n",
       "       (hook_q_input): HookPoint()\n",
       "       (hook_k_input): HookPoint()\n",
       "       (hook_v_input): HookPoint()\n",
       "       (hook_mlp_in): HookPoint()\n",
       "       (hook_attn_out): HookPoint()\n",
       "       (hook_mlp_out): HookPoint()\n",
       "       (hook_resid_pre): HookPoint()\n",
       "       (hook_resid_mid): HookPoint()\n",
       "       (hook_resid_post): HookPoint()\n",
       "     )\n",
       "   )\n",
       "   (ln_final): LayerNormPre(\n",
       "     (hook_scale): HookPoint()\n",
       "     (hook_normalized): HookPoint()\n",
       "   )\n",
       "   (unembed): Unembed()\n",
       " ),\n",
       " tensor([[    1,    10, 27498,  ...,    65, 32489,   426],\n",
       "         [    1, 14101, 27849,  ...,   282,  2374,   327],\n",
       "         [    1,  1358,   684,  ...,    10,  1320,    14],\n",
       "         ...,\n",
       "         [    1,  5613,   426,  ...,  1358,  7167,    65],\n",
       "         [    1,  4552,   324,  ...,  3270,  2012,    62],\n",
       "         [    1, 42978, 23925,  ...,  5181,    65,  3313]], device='cuda:0'),\n",
       " AutoEncoder())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_all(model_name=\"gelu-2l\", run=\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
