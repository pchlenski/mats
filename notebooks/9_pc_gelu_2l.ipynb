{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Changing model dtype to torch.float16\n",
      "Model device: cuda:0\n",
      "Tokens shape: torch.Size([215402, 128]), dtype: torch.int64, device: cuda:0\n",
      "{'act_name': 'blocks.1.hook_mlp_out',\n",
      " 'act_size': 512,\n",
      " 'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 512,\n",
      " 'device': 'cuda:0',\n",
      " 'dict_mult': 32,\n",
      " 'dict_size': 16384,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'layer': 1,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'model_name': 'gelu-2l',\n",
      " 'num_tokens': 2000000000,\n",
      " 'remove_rare_dir': False,\n",
      " 'seed': 50,\n",
      " 'seq_len': 128,\n",
      " 'site': 'mlp_out'}\n",
      "Encoder device: cuda:0\n",
      "{'act_name': 'blocks.0.hook_mlp_out',\n",
      " 'act_size': 512,\n",
      " 'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 512,\n",
      " 'device': 'cuda:1',\n",
      " 'dict_mult': 32,\n",
      " 'dict_size': 16384,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'layer': 0,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'model_name': 'gelu-2l',\n",
      " 'num_tokens': 2000000000,\n",
      " 'remove_rare_dir': False,\n",
      " 'seed': 51,\n",
      " 'seq_len': 128,\n",
      " 'site': 'mlp_out'}\n",
      "Encoder device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from sprint.loading import load_all, load_sae\n",
    "\n",
    "model, data, sae_l1 = load_all(model_name=\"gelu-2l\", run_id=\"l1\")\n",
    "sae_l0 = load_sae(run_id=\"l0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that it's two layers\n",
    "len(model.blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 2048])\n",
      "torch.Size([512, 16384])\n"
     ]
    }
   ],
   "source": [
    "# Shapes - gelu-2l\n",
    "\n",
    "print(model.blocks[0].mlp.W_in.shape)\n",
    "print(sae.W_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-1l into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Changing model dtype to torch.float16\n",
      "Model device: cuda:0\n",
      "Tokens shape: torch.Size([215402, 128]), dtype: torch.int64, device: cuda:0\n",
      "{'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 2048,\n",
      " 'dict_mult': 8,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'num_tokens': 2000000000,\n",
      " 'seed': 52,\n",
      " 'seq_len': 128}\n",
      "Encoder device: cuda:0\n",
      "torch.Size([512, 2048])\n",
      "torch.Size([2048, 16384])\n"
     ]
    }
   ],
   "source": [
    "# That doesn't look right... let's check this for the old model\n",
    "\n",
    "model, data, sae = load_all()\n",
    "\n",
    "print(model.blocks[0].mlp.W_in.shape)\n",
    "print(sae.W_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': tensor([ 0.0340,  0.0626,  0.0676,  ...,  0.1301, -0.0206,  0.0258],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>),\n",
       " 'sae activations': tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1543, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0117, 0.0000]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<ReluBackward0>),\n",
       " 'domain': tensor([ 2.1805e-02, -4.8462e-02,  1.9946e-01,  2.5977e-01,  3.3417e-02,\n",
       "         -7.5073e-02, -1.3672e-01,  1.1084e-01, -1.6577e-01,  1.0535e-01,\n",
       "          1.1176e-01, -3.1445e-01, -1.1035e-01,  3.7155e-03,  1.6016e-01,\n",
       "          9.6802e-02, -5.1270e-02, -9.2590e-02, -1.1841e-01,  1.1920e-01,\n",
       "          1.7261e-01, -5.5695e-02, -7.4158e-02, -8.7952e-02, -7.7881e-02,\n",
       "         -4.4409e-01, -3.1274e-01,  2.0477e-02, -2.7295e-01, -5.9998e-02,\n",
       "         -2.8687e-02,  2.8613e-01, -9.5850e-01, -1.4966e-01, -7.5134e-02,\n",
       "          3.1677e-02, -1.1969e-01, -2.6465e-01, -1.5173e-01, -1.7322e-01,\n",
       "         -1.3403e-01,  5.3101e-02, -1.9312e-01, -5.4443e-02,  1.3538e-01,\n",
       "         -1.1497e-02,  7.0496e-02,  1.5996e+00, -1.0840e-01, -6.2027e-03,\n",
       "         -2.2278e-01,  1.5088e-01,  2.3584e-01,  5.9052e-02,  1.3110e-01,\n",
       "          2.2717e-01,  5.9570e-02,  6.4636e-02,  3.3020e-02, -1.0175e-01,\n",
       "          1.4514e-01, -2.2498e-01,  1.2396e-01,  3.6035e-01,  2.6831e-01,\n",
       "         -2.7930e-01,  1.5137e-02,  2.1582e-01,  3.1174e-02, -3.6914e-01,\n",
       "          7.3730e-02, -2.2793e-03, -3.1348e-01,  1.0602e-01, -1.3843e-01,\n",
       "         -8.3923e-02, -8.0948e-03,  6.8115e-02,  7.0557e-02, -8.6548e-02,\n",
       "         -1.2878e-01,  9.4070e-03, -7.7881e-02,  2.4707e-01, -1.0974e-01,\n",
       "          9.3689e-02,  4.9805e-02, -2.4365e-01,  7.4341e-02, -1.2500e-01,\n",
       "          2.3026e-02,  8.3923e-02,  1.3440e-01, -1.1694e-01,  2.4866e-01,\n",
       "         -1.7624e-02,  2.9810e-01,  4.5593e-02, -1.6199e-01,  3.2406e-03,\n",
       "          1.4819e-01,  1.0504e-01, -3.6035e-01, -1.9312e-01, -3.4717e-01,\n",
       "         -9.2224e-02,  3.7537e-02, -1.6077e-01,  1.6907e-01,  2.1399e-01,\n",
       "         -1.1945e-01,  1.5723e-01,  2.5122e-01,  6.2683e-02,  2.2998e-01,\n",
       "         -2.3999e-01, -2.5391e-01,  5.9784e-02,  6.9153e-02,  1.4062e-01,\n",
       "         -2.1179e-02,  2.9956e-01,  2.2266e-01,  1.1652e-01, -1.1663e-03,\n",
       "          1.1346e-01,  1.5210e-01, -8.1787e-02, -2.2864e-01,  2.8442e-01,\n",
       "         -1.2598e-01,  3.0640e-01, -1.3147e-01, -1.0565e-01, -1.6455e-01,\n",
       "         -2.7969e-02,  1.1810e-02, -1.1658e-01,  7.8430e-02,  3.5205e-01,\n",
       "         -1.6479e-01,  3.0945e-02,  1.3318e-01, -9.8999e-02, -3.8452e-02,\n",
       "          1.5820e-01, -1.7651e-01, -1.7883e-01,  1.2134e-01, -1.8164e-01,\n",
       "          8.0261e-03, -7.7454e-02,  3.0103e-01, -2.8418e-01,  3.8257e-01,\n",
       "          1.9970e-03, -1.3232e-01, -1.8225e-01, -7.7148e-02, -1.0513e-02,\n",
       "         -2.5195e-01,  2.6880e-01, -1.4050e-01,  7.1045e-02,  2.7124e-01,\n",
       "          1.6375e-03, -6.7055e-05, -2.2034e-01,  1.5967e-01, -3.2845e-03,\n",
       "         -5.9235e-02,  7.4768e-02,  2.9932e-01, -4.0222e-02,  1.5454e-01,\n",
       "          1.9470e-01,  2.9346e-01,  1.5564e-02,  2.0862e-01, -2.4207e-01,\n",
       "         -4.1138e-02, -8.8989e-02,  1.2048e-01, -3.0777e-02, -8.7463e-02,\n",
       "         -1.6650e-01, -2.1094e-01,  1.7004e-01,  9.1125e-02,  5.5389e-02,\n",
       "         -1.1981e-01, -1.0455e-01, -1.1255e-01, -8.8562e-02,  9.3889e-04,\n",
       "          7.2632e-02,  3.7988e-01,  2.6760e-03, -4.3427e-02,  1.6321e-01,\n",
       "          6.2164e-02,  1.7798e-01,  2.7222e-01, -2.3999e-01, -1.4221e-01,\n",
       "         -8.7646e-02,  1.3086e-01, -1.0547e-01,  1.8750e-01,  7.7148e-02,\n",
       "          7.0618e-02, -8.8501e-02, -2.8610e-02, -9.1492e-02,  2.7856e-01,\n",
       "         -2.0349e-01,  2.7481e-02, -2.5833e-02,  1.2146e-01,  7.7087e-02,\n",
       "         -2.6123e-01, -2.3865e-01,  4.1626e-02,  1.1053e-01,  1.7285e-01,\n",
       "          1.2488e-01,  2.2998e-01,  4.1650e-01,  3.2056e-01, -2.6398e-03,\n",
       "          2.0068e-01, -1.4453e-01,  1.9299e-01,  1.8982e-01, -2.4744e-01,\n",
       "          2.2961e-01, -4.1595e-02,  3.5370e-02,  2.8418e-01,  1.7502e-02,\n",
       "         -1.3330e-01, -2.1167e-01,  6.8848e-02,  2.4878e-01, -2.2168e-01,\n",
       "          8.8257e-02,  7.6050e-02,  2.6270e-01,  3.1201e-01,  4.7760e-02,\n",
       "         -3.5706e-03,  3.0347e-01, -2.3267e-01,  1.0400e-01,  6.8970e-02,\n",
       "         -7.9712e-02,  1.9617e-01,  4.4373e-02, -1.5297e-02, -1.1401e-01,\n",
       "         -1.2321e-02, -2.8625e-02,  3.5004e-02, -5.8350e-02, -7.2998e-02,\n",
       "          3.3496e-01, -1.3525e-01,  7.8369e-02,  1.7319e-02,  8.7662e-03,\n",
       "         -2.9468e-01, -1.3855e-01, -1.6797e-01,  2.4451e-01,  9.6802e-02,\n",
       "          2.6099e-01,  1.1737e-01, -2.3120e-01, -1.6699e-01,  2.1545e-01,\n",
       "          6.4209e-02, -2.0798e-02,  5.1056e-02,  2.9785e-01, -2.9526e-02,\n",
       "         -4.6661e-02, -6.9153e-02,  2.4780e-01, -7.1533e-02, -1.6150e-01,\n",
       "         -8.8440e-02,  3.6713e-02,  2.2632e-01,  1.6064e-01,  7.9224e-02,\n",
       "         -9.2407e-02,  4.2694e-02, -3.6957e-02, -6.6711e-02, -1.5625e-01,\n",
       "          2.7981e-03, -1.9495e-01, -2.2009e-01,  7.5623e-02, -2.1500e-02,\n",
       "          1.6174e-01,  1.7737e-01, -1.2225e-01, -8.1726e-02, -3.7781e-02,\n",
       "          1.2354e-01, -7.7393e-02, -9.5749e-03, -3.6719e-01,  2.9984e-02,\n",
       "         -1.2794e-02, -5.4474e-02,  5.4260e-02,  1.9336e-01,  1.0541e-01,\n",
       "         -4.1626e-02,  5.0323e-02, -6.1188e-02, -1.9153e-01,  1.6317e-03,\n",
       "         -2.0667e-01, -1.4575e-01, -2.4719e-01,  7.3318e-03, -5.3406e-02,\n",
       "          3.4692e-01, -1.8872e-01, -2.2705e-01, -3.5583e-02, -1.1328e-01,\n",
       "         -6.1249e-02,  5.8838e-02,  1.1017e-01, -4.1479e-01, -4.8645e-02,\n",
       "         -8.7402e-02,  1.8250e-01,  1.0065e-01,  5.9967e-02,  1.9714e-02,\n",
       "          2.0642e-01, -1.3062e-01,  2.1277e-01,  4.6069e-01,  1.1707e-01,\n",
       "          1.9495e-01, -2.8296e-01,  2.0020e-01,  2.1561e-02, -1.1206e-03,\n",
       "         -1.6980e-01,  5.2460e-02, -1.7639e-01, -3.0701e-02,  1.2274e-01,\n",
       "         -3.7811e-02,  1.6754e-02, -3.6652e-02, -2.9443e-01, -1.4392e-01,\n",
       "          6.8542e-02, -2.5024e-01,  2.0671e-04, -2.7100e-01, -9.8206e-02,\n",
       "          5.9143e-02, -5.7739e-02, -4.7668e-02, -2.8003e-01,  1.1652e-01,\n",
       "          3.6377e-02,  1.0229e-01, -1.9910e-01, -1.8173e-02,  1.0126e-01,\n",
       "          4.3915e-02,  2.5269e-01,  1.0535e-01, -3.2562e-02,  1.5266e-02,\n",
       "         -1.0938e-01, -1.6797e-01,  4.7913e-03,  1.4575e-01,  5.6671e-02,\n",
       "         -9.6283e-03,  2.7686e-01,  5.1605e-02, -6.9824e-02, -5.6549e-02,\n",
       "         -5.3040e-02, -1.5015e-01, -1.5601e-01,  4.2542e-02, -3.9635e-03,\n",
       "         -1.5771e-01,  3.9856e-02, -6.6467e-02,  8.3252e-02,  1.8921e-01,\n",
       "          1.1926e-01,  1.5747e-01,  5.1613e-03, -1.7395e-02, -5.3192e-02,\n",
       "          1.3416e-01,  1.2329e-01, -1.2939e-01, -3.2935e-01, -1.1432e-01,\n",
       "          1.9653e-01, -7.8003e-02,  9.6680e-02,  7.1228e-02,  2.0593e-01,\n",
       "         -4.0039e-02, -2.3682e-02, -2.6978e-01, -4.3701e-01,  1.5991e-01,\n",
       "          5.0354e-02, -2.2507e-02, -2.0911e-01,  1.6760e-01, -8.2397e-02,\n",
       "          2.0264e-01,  8.5693e-02, -5.7709e-02,  1.7655e-04, -2.7539e-01,\n",
       "          6.8054e-02,  4.0894e-02,  3.5034e-02,  9.4177e-02,  1.5503e-01,\n",
       "         -3.8605e-02, -2.9248e-01,  1.2634e-01, -8.3191e-02, -8.3191e-02,\n",
       "          8.1543e-02,  5.9662e-02,  4.2633e-02, -1.5271e-01,  1.1940e-02,\n",
       "         -1.1865e-01, -9.7656e-02, -1.7262e-03,  1.8335e-01, -5.7678e-02,\n",
       "          2.9614e-01,  2.0776e-01, -1.4771e-01,  2.3962e-01, -1.9458e-01,\n",
       "         -1.4282e-01, -1.4771e-01, -1.1182e-01, -2.0007e-01,  1.0429e-02,\n",
       "         -2.0233e-02, -2.3120e-01, -1.6858e-01,  5.3925e-02, -2.0325e-01,\n",
       "         -3.8910e-02,  1.6650e-01,  1.8262e-01,  6.3904e-02,  2.3102e-02,\n",
       "         -8.5999e-02, -2.5537e-01, -3.5913e-01,  1.4744e-03,  3.0701e-02,\n",
       "         -1.2189e-01, -1.8127e-01,  2.0374e-01, -6.6956e-02,  3.4607e-02,\n",
       "          1.1096e-01, -3.0029e-01, -8.1116e-02,  1.5747e-02, -4.6754e-04,\n",
       "         -1.9397e-01,  5.8289e-02,  8.9111e-02,  1.3354e-01,  1.2659e-01,\n",
       "         -2.8979e-01, -3.2397e-01, -4.8981e-02, -1.1511e-01, -2.8290e-02,\n",
       "         -2.0532e-01, -2.0801e-01, -1.8518e-01,  3.6377e-01,  9.4116e-02,\n",
       "          7.3975e-02,  9.4543e-02, -1.4636e-01, -2.6440e-01,  7.0557e-02,\n",
       "         -1.4458e-03, -4.5052e-03], device='cuda:0', dtype=torch.float16,\n",
       "        grad_fn=<SqueezeBackward4>),\n",
       " 'mid': tensor([ 6.0303e-02, -1.6589e-01, -2.7710e-01, -1.8713e-01, -2.2690e-02,\n",
       "         -1.4160e-01,  3.2031e-01, -4.0210e-01, -6.3904e-02, -3.3228e-01,\n",
       "         -1.1340e-01, -2.9614e-01,  1.8933e-01,  2.9834e-01,  4.2090e-01,\n",
       "          4.3530e-01, -3.9111e-01, -3.6768e-01,  3.7231e-02,  1.3770e-01,\n",
       "         -8.3313e-02,  9.1943e-01,  4.4702e-01,  3.1647e-02,  3.4033e-01,\n",
       "          5.2246e-01, -2.2375e-01, -1.5063e-01, -7.0996e-01,  7.7454e-02,\n",
       "          3.7036e-01,  3.6426e-01, -5.0000e-01, -2.1866e-02,  1.9897e-01,\n",
       "          1.7993e-01, -5.2979e-01, -1.8091e-01,  4.8187e-02,  7.4646e-02,\n",
       "          1.4966e-01, -1.5002e-01, -2.2327e-01,  1.6626e-01, -1.0468e-01,\n",
       "         -4.2432e-01,  6.3525e-01, -8.1104e-01,  4.7485e-01,  9.7168e-02,\n",
       "          3.2764e-01, -2.2388e-01, -1.2390e-01, -2.0520e-01,  3.0737e-01,\n",
       "          4.6173e-02, -1.5869e-01,  1.8469e-01,  4.2358e-01,  4.0601e-01,\n",
       "         -3.4729e-02,  1.3428e-01,  2.9922e-02, -2.6367e-01,  1.1273e-01,\n",
       "          3.4302e-01, -5.1855e-01, -5.3131e-02,  3.9062e-01,  1.1774e-01,\n",
       "         -9.6289e-01, -4.8828e-01,  1.3489e-01,  3.7842e-01, -1.9775e-01,\n",
       "         -4.3628e-01, -5.9961e-01,  7.2949e-01,  1.9592e-01,  7.5391e-01,\n",
       "          1.3416e-01,  2.5781e-01, -7.6477e-02,  1.0713e+00, -3.9380e-01,\n",
       "         -6.4331e-02,  2.4622e-01, -3.6987e-01, -8.9551e-01,  5.3125e-01,\n",
       "          1.3281e-01, -1.3892e-01,  2.3486e-01, -1.3574e-01,  6.8848e-02,\n",
       "          2.6733e-02, -8.5327e-02, -2.7197e-01,  5.7869e-03, -4.0308e-01,\n",
       "          6.6910e-03,  4.0601e-01, -1.8420e-01,  6.0645e-01, -3.9722e-01,\n",
       "          1.4966e-01, -1.6919e-01,  1.0126e-01, -5.8545e-01, -5.7892e-02,\n",
       "          2.1387e-01, -4.5410e-01,  3.3142e-02, -1.5759e-01, -1.4551e-01,\n",
       "          4.6558e-01, -3.5010e-01,  5.3613e-01, -6.8457e-01,  3.2739e-01,\n",
       "          4.6460e-01, -4.2944e-01, -2.6138e-02, -3.3521e-01,  1.2341e-01,\n",
       "         -4.5435e-01,  4.9219e-01, -1.7767e-03, -2.2049e-02, -1.4746e-01,\n",
       "          4.4116e-01, -1.0508e+00,  7.9248e-01,  1.5356e-01,  2.8979e-01,\n",
       "          5.4248e-01, -2.1643e-01, -6.0913e-02, -2.7070e+00,  2.5818e-02,\n",
       "          4.7803e-01,  8.3252e-02, -1.2627e+00,  1.4990e-01,  6.3623e-01,\n",
       "          1.5820e-01, -1.3489e-01, -2.0435e-01,  7.3425e-02,  1.0284e-01,\n",
       "         -4.2676e-01, -3.5938e-01,  1.1969e-01,  1.2323e-01, -5.6610e-03,\n",
       "         -8.1970e-02, -7.4158e-02,  4.8682e-01,  1.9885e-01,  6.1377e-01,\n",
       "         -1.1035e-01, -1.7322e-01,  3.7036e-01,  8.1055e-02,  1.3733e-01,\n",
       "         -1.8884e-01, -4.0869e-01,  7.1143e-01,  1.0211e-01, -2.6050e-01,\n",
       "          1.0352e-01, -2.5955e-02,  9.0332e-02, -3.5400e-01, -5.7080e-01,\n",
       "          5.9912e-01,  6.5735e-02,  3.3032e-01, -1.7993e-01, -2.0544e-01,\n",
       "          4.1211e-01,  5.5469e-01, -1.1896e-01,  4.0527e-01, -5.0720e-02,\n",
       "         -7.7002e-01,  3.8452e-01,  8.3862e-02, -8.8196e-02,  2.7734e-01,\n",
       "          1.5674e-01, -2.0447e-01, -1.2842e-01,  5.5029e-01, -2.9614e-01,\n",
       "         -1.8909e-01,  1.9653e-02, -6.3770e-01,  8.1024e-03, -8.4412e-02,\n",
       "         -8.0859e-01,  1.2244e-01, -1.4880e-01,  5.8044e-02,  2.1130e-01,\n",
       "          1.0193e-02,  5.6934e-01,  1.1513e-02, -8.9258e-01, -4.6295e-02,\n",
       "         -3.4399e-01, -6.6260e-01, -2.3279e-01, -6.5918e-02, -3.6157e-01,\n",
       "          3.0136e-02,  1.3037e-01,  5.1660e-01,  8.2520e-02,  4.5337e-01,\n",
       "         -2.7441e-01, -5.6494e-01,  7.5012e-02, -3.7378e-01, -5.0146e-01,\n",
       "         -2.0764e-01,  5.9229e-01,  5.8899e-03, -3.1219e-02,  4.0747e-01,\n",
       "          9.1248e-02, -3.8647e-01,  1.0155e-02,  1.6064e-01,  3.5449e-01,\n",
       "          1.3367e-01, -7.9575e-03,  3.2788e-01, -1.9214e-01,  1.7944e-01,\n",
       "          2.1313e-01,  1.2090e+00, -4.1431e-01, -8.6060e-02,  3.4985e-01,\n",
       "          4.7437e-01,  1.0822e-01, -2.8906e-01, -7.6953e-01, -2.5781e-01,\n",
       "         -5.7666e-01, -2.3401e-01,  1.9360e-01, -3.4607e-02, -1.1032e-02,\n",
       "         -5.1807e-01, -1.9897e-01, -2.1960e-01,  3.2910e-01,  7.6318e-01,\n",
       "          3.2812e-01,  1.8176e-01,  3.6102e-02,  1.2610e-01, -1.1475e-01,\n",
       "         -1.2512e-01,  3.9966e-01, -2.7148e-01, -2.3315e-01,  8.7305e-01,\n",
       "          5.9143e-02,  4.7437e-01,  6.5039e-01,  4.8248e-02,  6.6528e-02,\n",
       "         -1.5762e+00, -4.7314e-01,  1.7627e-01, -6.7725e-01,  5.4016e-02,\n",
       "         -4.6191e-01,  3.1299e-01,  3.4424e-01,  2.8784e-01, -4.4995e-01,\n",
       "          4.6875e-02, -7.7209e-02,  3.9209e-01, -5.3558e-02,  4.7534e-01,\n",
       "          3.0322e-01,  3.2812e-01, -5.4443e-01, -6.6699e-01, -6.6211e-01,\n",
       "         -4.7021e-01, -2.2388e-01, -8.2812e-01, -4.9829e-01,  2.2461e-01,\n",
       "          3.8354e-01,  2.6343e-01, -4.9469e-02, -5.3131e-02,  4.5361e-01,\n",
       "         -7.7820e-02,  5.4395e-01, -5.2881e-01, -6.4551e-01,  5.3955e-01,\n",
       "          2.7148e-01, -5.6885e-02, -2.6245e-01, -9.6924e-02,  1.0376e-01,\n",
       "          4.0601e-01,  1.0605e+00, -2.4902e-02, -7.0117e-01, -2.2046e-01,\n",
       "         -3.1787e-01,  9.8828e-01,  6.3538e-02,  8.4656e-02,  1.7383e-01,\n",
       "          8.2910e-01, -2.8955e-01, -2.0544e-01,  2.7832e-02,  3.0542e-01,\n",
       "         -1.8701e-01,  2.3773e-02,  2.7539e-01, -1.8005e-01,  2.8223e-01,\n",
       "          4.4629e-01, -1.2383e+00,  1.2219e-01,  7.3926e-01,  1.0974e-01,\n",
       "         -1.0205e-01, -3.3081e-01, -3.2501e-02,  5.6190e-03, -3.7915e-01,\n",
       "          7.5500e-02,  3.2397e-01,  2.5562e-01, -4.8071e-01,  1.8298e-01,\n",
       "         -2.5806e-01,  1.5247e-01,  1.4417e-01,  4.3628e-01,  2.1338e-01,\n",
       "          4.7412e-01,  1.4502e-01, -3.4863e-01, -3.8379e-01, -4.3530e-01,\n",
       "          1.6162e-01,  2.5488e-01, -9.2102e-02,  2.3523e-01, -3.2104e-01,\n",
       "         -5.8197e-02,  3.0591e-01, -2.7588e-01, -2.6904e-01,  2.4524e-01,\n",
       "          2.2949e-01,  5.4785e-01, -1.9897e-01,  4.2871e-01,  3.5938e-01,\n",
       "         -3.4570e-01, -2.6758e-01, -1.5466e-01,  9.0149e-02, -1.0730e-01,\n",
       "         -2.5757e-01, -8.7219e-02, -2.6074e-01,  2.5073e-01, -2.5342e-01,\n",
       "          5.5127e-01,  3.9307e-01, -8.7598e-01, -2.7930e-01, -1.1459e-02,\n",
       "          1.6565e-01, -5.1514e-02, -3.2275e-01,  3.2202e-01,  1.7139e-01,\n",
       "          1.1835e-01,  4.4238e-01, -1.9348e-01, -5.1562e-01, -7.2314e-01,\n",
       "          5.8685e-02,  1.2781e-01,  7.2937e-02, -4.5728e-01, -8.0994e-02,\n",
       "          7.6904e-01, -5.5469e-01,  3.9136e-01,  2.4097e-01,  2.5586e-01,\n",
       "          3.5938e-01,  6.7773e-01, -2.6416e-01,  1.7725e-01,  4.6265e-01,\n",
       "          3.1395e-03,  8.3801e-02, -7.1533e-01, -1.0815e-01,  2.4707e-01,\n",
       "          3.0347e-01,  2.1179e-01,  6.4990e-01, -4.8126e-02, -1.9885e-01,\n",
       "         -3.1586e-02, -1.2170e-01, -4.0625e-01, -5.5115e-02,  4.2017e-01,\n",
       "         -2.6318e-01,  6.7334e-01,  3.9648e-01,  1.8347e-01, -2.7979e-01,\n",
       "          8.5022e-02,  2.5757e-01, -2.0532e-01, -5.5664e-01, -5.9692e-02,\n",
       "          1.5881e-01,  1.3208e-01,  5.5762e-01,  5.3076e-01,  2.4133e-01,\n",
       "         -4.1357e-01, -2.5317e-01, -3.1909e-01,  3.1470e-01,  4.2847e-02,\n",
       "         -5.2051e-01,  1.3555e+00, -2.1875e-01, -2.4612e-02,  4.1479e-01,\n",
       "         -4.5288e-01,  3.1921e-02,  8.1201e-01,  2.9224e-01, -1.1688e-01,\n",
       "         -9.1858e-02, -4.9243e-01,  1.9055e-01,  3.3081e-01, -3.6646e-01,\n",
       "         -2.2205e-01, -7.1289e-01,  1.5656e-02,  5.5518e-01,  2.5586e-01,\n",
       "          1.9495e-01,  1.2354e+00, -5.4004e-01, -7.1777e-01, -3.2812e-01,\n",
       "          3.6835e-02, -4.9756e-01, -9.2529e-02,  7.2070e-01,  7.3364e-02,\n",
       "         -2.3694e-01, -3.2593e-01, -3.4302e-01, -3.7378e-01, -1.1926e-01,\n",
       "          1.5762e-02, -2.0776e-01, -7.8857e-01,  5.7526e-02, -6.0120e-02,\n",
       "          2.0007e-01,  3.4033e-01, -5.1709e-01,  6.4307e-01,  4.6216e-01,\n",
       "         -3.3356e-02,  4.4775e-01, -8.8721e-01, -2.8198e-01,  7.5951e-03,\n",
       "         -1.9983e-01, -2.8247e-01, -4.2554e-01,  2.8735e-01, -1.0840e-01,\n",
       "         -1.0815e-01, -1.0999e-01,  6.2225e-02, -1.9043e-01,  2.2949e-01,\n",
       "         -1.8542e-01,  2.5171e-01], device='cuda:0', dtype=torch.float16),\n",
       " 'activation scores': tensor([-24.1719, -11.9297,  -5.0703,  ..., -18.4219,  -9.2266, -20.4531],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " 'tokens': tensor([-6.1172, -7.1836,  0.0198,  ...,  0.0903,  0.0997, -0.2507],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<MvBackward0>),\n",
       " 'token scores': tensor([10.7266, 10.5859, 10.4219, 10.4141, 10.2344, 10.0391, 10.0156,  9.8438,\n",
       "          9.8438,  9.8438], device='cuda:0', dtype=torch.float16,\n",
       "        grad_fn=<TopkBackward0>),\n",
       " 'token strings': [' incor',\n",
       "  ' Ske',\n",
       "  ' Sig',\n",
       "  ' asympt',\n",
       "  ' rés',\n",
       "  ' inex',\n",
       "  ' Coun',\n",
       "  ' исп',\n",
       "  ' pÃ',\n",
       "  ' unm'],\n",
       " 'OV unembed': tensor([-0.4236, -0.1781, -0.1031,  ..., -0.0234, -0.0251, -0.0029],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<SqueezeBackward1>),\n",
       " 'OV token scores': tensor([1.3789, 1.3525, 1.3516, 1.3496, 1.2988, 1.2793, 1.2725, 1.2646, 1.2568,\n",
       "         1.2529], device='cuda:0', dtype=torch.float16, grad_fn=<TopkBackward0>),\n",
       " 'OV token strings': ['USS',\n",
       "  ' Immigration',\n",
       "  'anov',\n",
       "  'LINE',\n",
       "  'rac',\n",
       "  'EL',\n",
       "  'opin',\n",
       "  'pec',\n",
       "  'FORMATION',\n",
       "  'sov'],\n",
       " 'ln+OV unembed': tensor([ 8.8440e-02, -6.4258e-01,  5.0391e-01, -4.3726e-01, -5.4346e-01,\n",
       "         -4.8737e-02,  2.8625e-02,  4.4922e-01, -4.7583e-01, -2.3877e-01,\n",
       "         -3.6841e-01,  1.1499e-01,  3.6084e-01,  2.8418e-01,  7.5391e-01,\n",
       "          3.7231e-01, -2.5684e-01, -2.8491e-01, -7.6355e-02, -3.4058e-01,\n",
       "          8.5742e-01,  8.0127e-01,  7.1973e-01, -5.8057e-01, -5.1910e-02,\n",
       "         -1.7017e-01,  5.0629e-02,  5.1074e-01, -3.8818e-01,  3.4204e-01,\n",
       "         -2.6294e-01, -3.7842e-01, -2.0593e-01, -1.7358e-01, -8.1787e-02,\n",
       "          4.1919e-01, -6.6064e-01, -7.8918e-02,  1.5625e-01,  8.8501e-02,\n",
       "         -1.8042e-01,  1.0608e-01,  2.3669e-01, -3.6987e-01,  6.6162e-01,\n",
       "         -4.2700e-01, -6.2805e-02,  7.4219e-02, -1.5491e-01, -6.2061e-01,\n",
       "         -6.2744e-01,  5.2051e-01, -8.5815e-02,  7.7441e-01,  4.8798e-02,\n",
       "          4.8730e-01,  2.3010e-01, -1.8829e-02,  5.3857e-01, -8.8440e-02,\n",
       "          3.6621e-01,  2.0432e-02, -5.0244e-01, -6.4844e-01, -5.4883e-01,\n",
       "         -2.8711e-01, -3.6816e-01,  8.8330e-01,  1.0094e-02,  4.5947e-01,\n",
       "          5.0146e-01, -2.4084e-01, -1.1163e-01,  3.3252e-01, -9.3701e-01,\n",
       "         -7.7576e-02,  9.6680e-02,  4.0308e-01,  2.7173e-01,  7.3291e-01,\n",
       "          2.6047e-02, -5.0098e-01,  1.7383e-01, -2.5488e-01, -1.1566e-01,\n",
       "         -3.1982e-01,  5.8643e-01, -1.7975e-02, -4.1333e-01,  8.3447e-01,\n",
       "          4.4629e-01, -1.9458e-01, -6.8066e-01,  1.6516e-01,  3.0713e-01,\n",
       "         -1.5356e-01,  2.1570e-01, -1.4539e-01, -5.8105e-01, -1.0126e-01,\n",
       "          5.4199e-01, -4.4238e-01,  4.6924e-01,  4.6216e-01, -1.1152e+00,\n",
       "         -4.3297e-03, -2.7759e-01, -1.3171e-01, -2.6489e-01,  3.0200e-01,\n",
       "         -1.0999e-01, -3.3789e-01,  2.6074e-01,  4.0234e-01,  9.7717e-02,\n",
       "          2.4634e-01,  5.8594e-01,  7.1777e-01, -1.6089e-01, -4.3237e-01,\n",
       "         -5.3223e-01, -2.5269e-01, -2.3413e-01, -7.0166e-01,  6.6833e-03,\n",
       "          4.0356e-01,  1.3418e+00,  4.6655e-01, -4.0619e-02, -1.3750e+00,\n",
       "          6.4307e-01, -4.5044e-02, -2.5562e-01,  1.6455e-01,  4.8047e-01,\n",
       "          6.5674e-01,  5.5518e-01, -6.1005e-02, -2.7191e-02, -5.0635e-01,\n",
       "          1.0567e-02,  6.9189e-01, -5.1172e-01,  1.6736e-01, -2.2180e-01,\n",
       "         -9.0381e-01, -1.1777e+00, -2.7527e-02, -7.3047e-01,  4.7632e-01,\n",
       "         -3.6963e-01, -3.5742e-01, -5.6836e-01,  5.2783e-01,  6.9397e-02,\n",
       "          3.2928e-02,  2.1045e-01, -3.7842e-01,  3.5791e-01, -2.0157e-02,\n",
       "          4.4891e-02,  1.6663e-01,  3.7671e-01,  2.1387e-01,  6.5857e-02,\n",
       "         -5.7556e-02, -2.5659e-01, -3.2886e-01,  3.3057e-01,  3.9868e-01,\n",
       "          3.1958e-01, -4.1016e-01, -2.4805e-01,  2.7319e-01, -1.4294e-01,\n",
       "          5.4932e-01,  2.4915e-01, -1.5833e-01,  9.7473e-02,  6.1133e-01,\n",
       "          1.6436e+00,  6.6357e-01, -6.4880e-02, -5.1074e-01, -4.4922e-01,\n",
       "          1.6284e-01,  5.7178e-01,  6.1279e-01, -2.0203e-01, -5.4047e-02,\n",
       "         -2.2888e-01,  7.0572e-03,  1.2292e-01,  3.3813e-01, -2.1899e-01,\n",
       "         -7.3486e-02,  2.2742e-01,  5.7227e-01, -2.4399e-02,  9.0088e-02,\n",
       "         -2.8369e-01,  2.8397e-02,  7.2510e-01,  3.0981e-01, -3.0225e-01,\n",
       "         -1.2781e-01, -6.3330e-01,  3.2568e-01, -1.7410e-02,  1.0869e+00,\n",
       "          1.1096e-01,  4.9268e-01,  2.8149e-01,  5.0195e-01, -5.0732e-01,\n",
       "         -2.4817e-01,  5.7764e-01,  3.5767e-01, -9.2480e-01, -3.7646e-01,\n",
       "          2.9663e-01, -4.5093e-01, -3.8574e-01, -3.4229e-01,  1.6492e-01,\n",
       "          6.6406e-02, -2.8320e-02, -1.5710e-01,  4.8120e-01, -1.0010e+00,\n",
       "          5.3857e-01, -4.5068e-01,  2.4414e-01, -3.5065e-02, -2.4353e-01,\n",
       "          5.5969e-02, -3.6523e-01, -3.4497e-01, -5.3955e-02,  2.9004e-01,\n",
       "          9.5764e-02,  7.1191e-01,  5.7800e-02,  2.6807e-01,  1.2490e+00,\n",
       "         -3.0563e-02,  1.4697e-01, -2.7100e-01,  6.5918e-03, -8.0566e-02,\n",
       "         -3.1201e-01,  5.3215e-03, -6.1719e-01, -4.0186e-01, -2.4121e-01,\n",
       "          1.4331e-01,  1.8176e-01, -5.1855e-01,  4.4604e-01,  5.7471e-01,\n",
       "          3.0444e-01,  2.0886e-01,  4.4580e-01, -3.4277e-01, -2.9541e-01,\n",
       "          7.5836e-03,  2.6050e-01, -1.5735e-01, -1.1926e-01, -4.6387e-02,\n",
       "          7.3486e-02, -2.0187e-02, -3.4210e-02, -4.7632e-01,  3.5620e-01,\n",
       "         -2.9517e-01, -4.9390e-01, -7.3181e-02,  4.4824e-01, -6.9336e-02,\n",
       "         -7.1228e-02,  2.2571e-01, -2.4890e-01,  4.8859e-02, -9.8975e-01,\n",
       "         -5.6787e-01,  3.9526e-01,  2.0740e-01, -2.2314e-01,  1.0059e-01,\n",
       "          5.0293e-01, -2.0374e-01,  1.9562e-02,  5.9570e-02, -2.8442e-01,\n",
       "         -2.7612e-01,  3.4009e-01,  5.6122e-02, -3.2153e-01, -4.5850e-01,\n",
       "         -3.6285e-02,  1.5121e-02,  3.4058e-02,  4.8730e-01,  4.6484e-01,\n",
       "         -8.0273e-01,  9.5764e-02, -5.3223e-01, -2.7148e-01, -2.8833e-01,\n",
       "          1.6504e-01,  4.3945e-01,  7.0312e-02,  9.0625e-01, -1.5198e-02,\n",
       "         -6.3086e-01,  1.0919e-01, -6.9385e-01,  6.9092e-02, -7.9980e-01,\n",
       "          2.3523e-01, -3.4302e-01,  2.3792e-01, -7.0190e-03,  7.3242e-01,\n",
       "          2.3987e-01, -5.5078e-01, -1.4514e-01, -8.4375e-01,  7.0410e-01,\n",
       "         -1.1511e-01, -4.2480e-01,  1.7505e-01,  3.8965e-01,  5.6982e-01,\n",
       "         -2.6880e-01,  1.5674e-01,  6.0596e-01, -1.0547e-01, -2.1704e-01,\n",
       "          5.4016e-03, -7.2266e-01, -5.2686e-01, -1.2280e-01, -3.8477e-01,\n",
       "         -6.0449e-01,  3.6401e-01,  4.2578e-01,  1.7163e-01, -9.6008e-02,\n",
       "         -9.9609e-01, -9.8096e-01, -2.1106e-01,  2.8412e-02, -1.4563e-01,\n",
       "         -7.5867e-02, -1.2244e-01,  2.2449e-01,  4.5557e-01,  3.3325e-01,\n",
       "         -4.6606e-01,  1.8359e-01, -6.4819e-02,  1.9150e-02,  1.0544e-02,\n",
       "          3.5767e-01,  4.9536e-01,  1.3806e-01, -1.8811e-01, -1.2988e-01,\n",
       "         -2.2720e-02,  3.9185e-01, -8.7305e-01,  4.5990e-02,  3.7598e-01,\n",
       "         -4.0405e-01, -5.6006e-01,  9.3628e-02,  1.0895e-01, -1.2457e-01,\n",
       "         -7.8223e-01,  5.0928e-01, -6.6833e-02,  5.1562e-01,  1.1792e-01,\n",
       "          1.0901e-01, -9.1064e-02,  1.3416e-01, -1.8835e-01, -1.0425e-01,\n",
       "         -1.6528e-01,  4.6680e-01,  4.6997e-01,  4.8389e-01, -4.0796e-01,\n",
       "         -1.6028e-01,  5.4150e-01, -8.8745e-02, -4.4849e-01,  4.3262e-01,\n",
       "          7.1094e-01,  3.3179e-01,  2.6147e-01, -1.9617e-01,  1.4978e-01,\n",
       "         -1.7664e-01,  4.8413e-01, -5.1651e-03, -5.7910e-01,  8.8721e-01,\n",
       "          2.2827e-01, -6.9238e-01, -8.1592e-01,  6.7383e-01,  3.3374e-01,\n",
       "         -3.1030e-01,  3.5828e-02,  2.7637e-01, -8.7256e-01,  4.3921e-01,\n",
       "          9.0527e-01,  1.1035e-01,  3.5913e-01,  1.9885e-01, -1.8408e-01,\n",
       "          3.7866e-01, -4.3213e-01, -1.6223e-01, -5.1367e-01, -1.6260e-01,\n",
       "         -7.1143e-01,  5.5908e-01, -2.4433e-03, -4.2163e-01, -5.2344e-01,\n",
       "          4.2627e-01,  3.6572e-01, -8.8623e-02, -5.3271e-01, -3.8452e-01,\n",
       "          1.4929e-01, -2.9639e-01, -8.1592e-01,  2.7686e-01, -8.8330e-01,\n",
       "          8.8928e-02,  1.8066e-01, -2.6123e-01,  4.0436e-03, -4.6021e-01,\n",
       "          2.4902e-01, -9.3985e-04,  4.8193e-01, -1.0480e-01, -1.8701e-01,\n",
       "          1.4600e-01, -2.0032e-01,  7.3730e-02, -3.4106e-01,  1.0566e+00,\n",
       "          4.1724e-01,  4.2992e-03, -1.0400e+00, -4.6924e-01,  4.0625e-01,\n",
       "         -5.0439e-01,  2.5293e-01,  2.1484e-01,  1.7126e-01,  4.9756e-01,\n",
       "         -2.9834e-01,  6.8848e-01, -1.9800e-01, -3.3936e-01,  4.4287e-01,\n",
       "          1.4062e-01,  2.3422e-02,  1.3574e-01,  4.2920e-01,  1.4111e-01,\n",
       "         -1.8298e-01, -4.8615e-02,  2.2241e-01,  8.9905e-02, -2.4731e-01,\n",
       "          1.7346e-01, -2.7783e-01,  2.6416e-01, -4.2212e-01, -4.9341e-01,\n",
       "         -4.1382e-01,  3.0444e-01,  7.4561e-01, -1.0645e+00,  9.6729e-01,\n",
       "          1.4233e-01, -3.5669e-01, -8.4595e-02, -6.2402e-01, -1.2415e-01,\n",
       "          1.6431e-01, -3.0273e-01, -9.0869e-01, -4.1016e-02, -4.1650e-01,\n",
       "         -2.4597e-01,  9.1125e-02, -3.7109e-01, -1.1398e-02,  3.6255e-01,\n",
       "          5.9668e-01,  4.5312e-01], device='cuda:0', dtype=torch.float16),\n",
       " 'ln+OV token scores': tensor([1.6436, 1.3418, 1.2490, 1.0869, 1.0566, 0.9673, 0.9062, 0.9053, 0.8872,\n",
       "         0.8833], device='cuda:0', dtype=torch.float16),\n",
       " 'ln+OV token strings': ['\\x02',\n",
       "  '�',\n",
       "  '�',\n",
       "  '\\x1f',\n",
       "  'ure',\n",
       "  'able',\n",
       "  'am',\n",
       "  'ment',\n",
       "  'rom',\n",
       "  'a'],\n",
       " 'QK unembed': tensor([ 0.5649,  0.4424, -0.0480,  ..., -0.0405,  0.0258, -0.0254],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<SqueezeBackward1>),\n",
       " 'QK token scores': tensor([1.1729, 1.1426, 1.1309, 1.1279, 1.1201, 1.1064, 1.0752, 1.0752, 1.0742,\n",
       "         1.0635], device='cuda:0', dtype=torch.float16, grad_fn=<TopkBackward0>),\n",
       " 'QK token strings': [' License',\n",
       "  ' Anti',\n",
       "  ' CRE',\n",
       "  ' Admin',\n",
       "  ' UPS',\n",
       "  ' Treasure',\n",
       "  ' programmable',\n",
       "  ' Sto',\n",
       "  ' automatic',\n",
       "  ' gad']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify linearization still works at L0\n",
    "\n",
    "from sprint.linearization import analyze_linearized_feature\n",
    "\n",
    "analyze_linearized_feature(\n",
    "    feature_idx=100,\n",
    "    sample_idx=30,\n",
    "    token_idx=30,\n",
    "    model=model,\n",
    "    data=data,\n",
    "    encoder=sae_l0,\n",
    "    layer=0,\n",
    "    batch_size=32,\n",
    "    n_tokens=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': tensor([ 0.0340,  0.0626,  0.0676,  ...,  0.1301, -0.0206,  0.0258],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>),\n",
       " 'sae activations': tensor([[17.1562, 27.7969, 26.9375,  ...,  0.0000,  0.0000, 36.5625],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<ReluBackward0>),\n",
       " 'domain': tensor([-3.8300e-02, -3.7573e-01, -3.3716e-01, -2.6074e-01,  4.0771e-01,\n",
       "          2.7100e-01,  1.9458e-01, -2.4731e-01, -6.2378e-02,  1.8213e-01,\n",
       "          2.7893e-02, -3.2928e-02, -6.9641e-02, -2.1631e-01,  4.9347e-02,\n",
       "          1.6833e-01, -9.8705e-04, -1.9080e-01,  1.2230e-02, -2.0508e-01,\n",
       "         -1.3611e-01,  5.3375e-02, -3.6108e-01,  2.6782e-01,  2.5708e-01,\n",
       "         -1.0034e-01,  7.4539e-03,  7.9468e-02, -8.0139e-02,  4.1064e-01,\n",
       "          1.0028e-01,  7.5867e-02,  2.7480e+00, -4.1290e-02,  2.4963e-01,\n",
       "         -1.5527e-01, -1.4771e-01, -1.3123e-01,  2.3941e-02, -2.5049e-01,\n",
       "         -6.2103e-03, -2.8711e-01, -5.2002e-01, -7.0117e-01, -3.2617e-01,\n",
       "         -1.2561e-01, -2.9956e-01, -1.8787e-01, -2.9126e-01,  1.8872e-01,\n",
       "          2.9678e-03,  7.2937e-02,  1.9910e-01, -4.0283e-01,  1.8433e-02,\n",
       "          4.9019e-03, -1.7664e-01,  8.8135e-02,  2.6099e-01, -2.2534e-01,\n",
       "         -2.5903e-01, -9.6741e-02,  4.2554e-01,  2.4994e-02,  5.7812e-01,\n",
       "          2.8271e-01, -1.7810e-01,  9.7046e-02,  4.0253e-02,  2.6025e-01,\n",
       "         -2.9224e-01,  1.1633e-01, -3.0005e-01,  2.2168e-01, -1.2024e-01,\n",
       "          3.8525e-01,  5.8044e-02,  2.2705e-01, -2.4967e-03,  5.8319e-02,\n",
       "         -1.2329e-01, -1.3382e-02, -6.9702e-02, -1.2793e-01, -2.1545e-01,\n",
       "         -3.5645e-01,  1.4355e-01, -3.5645e-01, -5.5420e-01,  3.1421e-01,\n",
       "          3.4302e-01,  4.4434e-02, -4.2310e-01,  2.7856e-01, -9.6680e-02,\n",
       "         -2.6855e-01, -1.3879e-01, -2.2974e-01,  1.3550e-01, -2.1802e-01,\n",
       "          7.9163e-02,  2.9248e-01,  3.0716e-02,  6.4111e-01,  2.6782e-01,\n",
       "          6.0449e-01, -2.6001e-01, -2.9739e-02, -4.1626e-01,  1.8030e-01,\n",
       "         -4.4971e-01,  5.2197e-01,  4.3115e-01,  2.5049e-01,  2.0044e-01,\n",
       "          1.7380e-02, -1.6260e-01, -2.4561e-01, -1.6223e-01,  5.6396e-01,\n",
       "          1.0231e-02,  2.3230e-01, -5.5054e-02,  1.8530e-01,  1.0803e-01,\n",
       "          9.1614e-02,  1.2622e-01, -4.0405e-02,  4.5959e-02, -6.6345e-02,\n",
       "          8.0566e-02, -2.6147e-01, -6.7200e-02,  7.6843e-02,  7.0801e-02,\n",
       "         -1.3977e-01, -1.0919e-01, -3.5938e-01, -5.4639e-01,  3.7061e-01,\n",
       "          3.7866e-01, -1.8689e-01, -4.9316e-02,  2.6636e-01, -5.2832e-01,\n",
       "          4.3121e-02, -3.7256e-01,  9.1003e-02,  1.9608e-02,  2.4426e-01,\n",
       "         -3.1665e-01, -7.2693e-02, -6.7200e-02, -3.4607e-02, -1.3220e-01,\n",
       "         -2.5928e-01, -7.6721e-02, -9.0039e-01,  2.1057e-01,  1.7017e-01,\n",
       "          3.2251e-01,  1.5271e-01,  3.9624e-01, -1.1523e-01, -2.6636e-01,\n",
       "         -2.8052e-01,  9.6313e-02, -2.0538e-02, -4.2896e-01,  2.0093e-01,\n",
       "          2.4255e-01,  1.6272e-01, -2.3682e-01,  1.5637e-01, -1.2805e-01,\n",
       "          4.4495e-02, -2.5024e-01,  9.8877e-02, -2.5269e-01, -2.0398e-01,\n",
       "          4.7607e-01,  3.6011e-01,  2.0874e-01, -1.6785e-01, -2.0569e-01,\n",
       "         -4.8315e-01,  1.4038e-01, -1.6284e-01, -3.9575e-01, -6.9641e-02,\n",
       "          3.1592e-01,  2.0911e-01, -2.0288e-01,  1.5552e-01, -1.2769e-01,\n",
       "          6.6284e-02, -3.3960e-01, -1.9409e-01, -1.7380e-02,  2.5317e-01,\n",
       "         -2.7173e-01, -8.3191e-02, -1.5442e-01,  2.6718e-02,  1.8158e-02,\n",
       "          9.9915e-02,  3.3301e-01, -6.4331e-02, -2.0679e-01,  9.8633e-02,\n",
       "         -9.6008e-02,  2.6343e-01,  2.3328e-01,  2.0215e-01,  3.7061e-01,\n",
       "          2.5375e-02, -4.6680e-01,  2.5610e-01,  3.7012e-01, -7.4585e-02,\n",
       "         -9.8267e-02,  1.3562e-01, -2.6270e-01, -1.7975e-02, -5.0439e-01,\n",
       "         -9.2529e-02,  2.1301e-01,  2.8540e-01, -1.0144e-01, -1.4331e-01,\n",
       "          5.2490e-01, -6.4502e-01,  8.8196e-02, -3.1189e-02, -2.2180e-01,\n",
       "         -3.0933e-01,  4.8096e-02,  4.9683e-01, -9.5215e-02, -7.5867e-02,\n",
       "         -3.9246e-02, -3.4570e-01,  2.8613e-01, -1.0541e-01, -5.2588e-01,\n",
       "          9.0271e-02, -4.4165e-01,  4.3506e-01,  4.8120e-01, -4.0039e-01,\n",
       "         -1.7590e-01,  2.2595e-01,  1.8835e-01,  2.2375e-01, -7.9407e-02,\n",
       "         -2.5439e-01,  7.4768e-02, -4.7388e-01, -1.4746e-01,  7.0801e-02,\n",
       "          1.3452e-01, -3.2739e-01, -1.8463e-02, -8.4778e-02, -3.7988e-01,\n",
       "          1.8152e-01, -4.3274e-02, -7.4756e-01,  1.5454e-01,  3.1079e-01,\n",
       "          1.3660e-01,  5.1788e-02,  3.4485e-02, -4.7333e-02, -1.7444e-01,\n",
       "          2.0569e-02, -1.9397e-01, -2.8369e-01,  3.2739e-01, -1.9946e-01,\n",
       "         -4.0454e-01,  3.6774e-02,  2.2241e-01, -4.6051e-02,  1.6895e-01,\n",
       "         -5.1514e-02,  5.8496e-01,  3.7964e-01, -4.4263e-01,  1.4929e-01,\n",
       "          9.9915e-02, -1.1700e-01, -3.6108e-01, -2.7783e-01,  4.1260e-01,\n",
       "          3.9478e-01, -9.9670e-02,  1.3696e-01, -1.9714e-01,  3.4473e-01,\n",
       "          1.5533e-02,  3.2031e-01, -2.1558e-01, -8.0627e-02,  1.3098e-01,\n",
       "          2.5146e-01,  1.0406e-01,  5.4901e-02, -3.4790e-01,  2.3291e-01,\n",
       "          5.4138e-02,  9.0637e-03, -1.7563e-02,  1.0236e-01,  2.2791e-01,\n",
       "         -7.4951e-02,  1.6028e-01, -3.8428e-01,  2.5024e-01,  2.4475e-01,\n",
       "         -3.9575e-01,  1.3403e-01,  1.4172e-01,  6.0913e-02,  2.5317e-01,\n",
       "         -1.2749e-02, -4.4751e-01, -3.9136e-01,  1.1353e-01, -2.3706e-01,\n",
       "         -7.5745e-02, -2.8979e-01,  2.0676e-03,  1.3779e-02, -3.1079e-01,\n",
       "          6.7261e-02, -7.3669e-02,  4.3091e-02, -2.1820e-02, -4.4653e-01,\n",
       "         -3.0444e-01, -4.6289e-01, -1.2842e-01, -1.0010e-01, -1.2915e-01,\n",
       "         -1.8542e-01,  1.4221e-01,  4.5483e-01,  4.6021e-01,  9.8267e-02,\n",
       "          1.9373e-01, -1.8127e-01, -1.6772e-01,  2.1448e-01,  3.3105e-01,\n",
       "          8.1360e-02, -1.0388e-01, -3.8623e-01,  4.5605e-01, -1.1774e-01,\n",
       "         -1.9043e-01,  5.1941e-02, -2.5122e-01, -8.8196e-02,  5.6055e-01,\n",
       "          9.1675e-02, -1.8274e-01,  4.5459e-01, -1.6296e-01,  1.2073e-01,\n",
       "         -1.7114e-01,  9.1736e-02, -9.1553e-02,  4.2554e-01,  3.8269e-02,\n",
       "          5.1498e-04,  1.1371e-01, -9.4055e-02, -3.4058e-01, -2.0325e-01,\n",
       "         -7.3853e-02,  3.7256e-01,  3.7524e-01,  2.4182e-01, -1.8173e-02,\n",
       "          2.2388e-01,  1.1920e-01, -7.9529e-02,  2.8784e-01,  6.0693e-01,\n",
       "         -5.6946e-02, -3.8745e-01, -1.8689e-01,  1.5369e-01, -4.4098e-02,\n",
       "          2.0886e-01,  1.3452e-01,  3.1799e-02,  1.6577e-01,  7.9346e-02,\n",
       "         -4.1040e-01, -4.4289e-03, -2.6611e-01, -5.3467e-01,  2.4951e-01,\n",
       "         -3.6035e-01, -1.9202e-01,  2.4628e-02, -1.8152e-01,  1.6003e-01,\n",
       "         -6.4270e-02,  3.8281e-01,  1.8298e-01,  1.3232e-01, -2.0947e-01,\n",
       "          2.2156e-01,  3.2990e-02,  1.0291e-01,  7.3242e-02,  2.2900e-01,\n",
       "          5.5298e-02,  1.3857e-03, -1.1017e-01, -1.6321e-01, -1.9852e-02,\n",
       "          3.2397e-01,  3.1860e-01,  2.8516e-01,  3.0518e-01,  7.5195e-02,\n",
       "         -2.0564e-04, -5.4053e-01,  1.4978e-01, -1.6016e-01,  3.3374e-01,\n",
       "          8.3984e-02, -3.7964e-01, -1.4999e-02,  2.1667e-01,  6.2164e-02,\n",
       "          1.0498e-01, -7.5012e-02, -1.5173e-01, -1.6394e-01, -6.2012e-02,\n",
       "          1.8201e-01, -1.4856e-01, -3.9795e-01,  9.0881e-02, -4.4769e-02,\n",
       "          1.9751e-01,  9.6558e-02, -3.2300e-01, -1.8701e-01, -3.4521e-01,\n",
       "         -3.7769e-01,  1.8823e-01,  5.9021e-02, -9.9902e-01, -4.9976e-01,\n",
       "         -1.8054e-01, -5.0812e-02, -4.0161e-02,  2.0959e-01,  8.2947e-02,\n",
       "         -2.0972e-01,  4.2297e-02, -3.0542e-01,  1.3330e-01,  6.3782e-02,\n",
       "         -2.5220e-01,  3.2935e-01, -4.8126e-02,  3.8940e-02,  3.8086e-01,\n",
       "         -3.0884e-01,  1.1664e-01,  9.9976e-02,  1.0168e-01, -1.9855e-03,\n",
       "          5.9619e-01,  2.1716e-01, -3.8013e-01, -2.2934e-02,  1.8677e-01,\n",
       "          1.1517e-01, -2.3657e-01, -2.2964e-02, -1.9043e-01, -2.4231e-02,\n",
       "          2.6221e-01,  1.6052e-02,  2.4231e-01,  3.0615e-01,  1.2512e-01,\n",
       "          1.7407e-01,  7.3242e-02, -2.5903e-01, -2.2717e-03, -2.2070e-01,\n",
       "          1.9678e-01, -2.2473e-01,  4.9774e-02,  8.5022e-02,  3.7720e-01,\n",
       "          5.2521e-02,  3.8525e-01,  3.9209e-01,  2.0605e-01,  3.4448e-01,\n",
       "         -2.7197e-01,  4.6143e-02], device='cuda:0', dtype=torch.float16,\n",
       "        grad_fn=<SqueezeBackward4>),\n",
       " 'mid': tensor([ 1.3135e-01,  1.7822e-01, -8.1116e-02, -2.7893e-02,  1.2695e-01,\n",
       "         -9.1309e-02,  1.5480e-02, -8.9294e-02,  1.2408e-01, -2.8613e-01,\n",
       "          1.4917e-01, -6.7635e-03,  1.7410e-02, -8.1726e-02, -1.2494e-01,\n",
       "          2.1606e-02,  5.9601e-02,  3.6373e-03, -7.0114e-03,  2.4612e-02,\n",
       "         -8.2275e-02,  8.5022e-02, -2.9266e-02,  5.3986e-02,  7.7133e-03,\n",
       "          5.5359e-02,  3.1067e-02, -1.0919e-01,  3.2654e-02,  3.1769e-02,\n",
       "          2.0923e-01,  4.2542e-02, -4.1968e-01,  4.1199e-02,  3.4241e-02,\n",
       "         -7.2510e-02,  3.7048e-02,  7.8430e-02,  1.2337e-02,  4.8401e-02,\n",
       "          5.5389e-03,  2.9999e-02,  1.0675e-01, -1.2390e-01, -5.2910e-03,\n",
       "          1.5906e-01,  4.9133e-02, -1.5297e-02,  8.7051e-03,  9.4482e-02,\n",
       "         -1.3757e-01,  2.2812e-02, -7.4890e-02,  7.1533e-02, -1.6553e-01,\n",
       "          1.3354e-01, -2.4292e-02, -1.0992e-01,  5.8365e-03, -1.2347e-01,\n",
       "         -8.3313e-02, -6.5155e-03, -1.3330e-01, -1.2805e-01, -3.8696e-02,\n",
       "          2.1957e-02, -9.0637e-02,  8.5144e-02,  2.3544e-02,  1.5527e-01,\n",
       "         -2.1643e-01,  1.8408e-01,  1.1548e-01,  4.8920e-02,  7.6111e-02,\n",
       "          8.8257e-02,  6.6772e-02,  2.7176e-02, -4.7089e-02, -4.1870e-02,\n",
       "          3.6987e-02,  3.0766e-03, -7.5989e-02,  3.6774e-02,  1.0828e-01,\n",
       "          1.2352e-02, -1.4030e-02,  3.3844e-02,  5.9753e-02, -2.1155e-01,\n",
       "          6.0669e-02, -4.9622e-02, -5.7159e-02, -3.2080e-01,  1.1737e-01,\n",
       "          5.4443e-02, -1.0986e-01, -8.7769e-02, -7.9163e-02, -7.3120e-02,\n",
       "         -1.1432e-01, -8.4778e-02,  1.3464e-01,  1.3153e-02,  1.4185e-01,\n",
       "          1.5518e-02,  1.7615e-01,  1.3611e-01, -3.1519e-01, -7.1167e-02,\n",
       "          2.0142e-01, -9.8083e-02, -1.3464e-01, -5.1880e-02,  7.2998e-02,\n",
       "         -1.0498e-02, -4.0527e-02, -6.8848e-02, -7.3486e-02, -3.3661e-02,\n",
       "          1.8567e-01, -2.0370e-02,  1.0443e-01,  2.0691e-02,  1.8433e-01,\n",
       "         -1.6464e-02, -1.2787e-02, -1.5961e-02,  9.5154e-02,  9.1980e-02,\n",
       "          1.0645e-01,  9.4376e-03,  1.6699e-01, -3.7415e-02,  3.3234e-02,\n",
       "         -2.7100e-01,  1.0187e-01, -1.2891e-01,  1.8951e-02, -1.5588e-01,\n",
       "          1.4319e-01, -6.4545e-03,  1.3477e-01, -6.9580e-02,  1.8481e-01,\n",
       "          1.1829e-01,  4.1870e-02,  4.4220e-02, -1.4966e-01,  3.8635e-02,\n",
       "         -3.8757e-02,  1.4067e-03,  1.6089e-01, -2.6294e-01, -2.3834e-02,\n",
       "          1.7236e-01,  2.6550e-02,  1.0883e-01,  3.8269e-02, -2.5070e-02,\n",
       "         -9.1553e-03, -1.0522e-01,  6.6528e-02, -7.0679e-02, -8.2397e-03,\n",
       "          4.6936e-02, -6.7261e-02,  2.6566e-02, -8.4534e-02, -1.0590e-01,\n",
       "          2.3047e-01,  6.5735e-02, -7.2083e-02, -3.9429e-02, -1.0297e-01,\n",
       "         -1.3696e-01,  4.5959e-02, -2.8702e-02,  3.3020e-02, -8.2397e-02,\n",
       "          4.8065e-02,  3.5706e-02, -2.0776e-01, -7.9498e-03, -1.4526e-01,\n",
       "         -1.4587e-01, -4.5586e-03, -1.1554e-01, -7.7454e-02,  1.2238e-01,\n",
       "         -1.0809e-01, -1.3025e-01, -4.6265e-02,  6.5186e-02,  8.7891e-02,\n",
       "         -7.0618e-02, -8.0383e-02, -4.6570e-02, -3.3234e-02, -5.1941e-02,\n",
       "         -6.7505e-02, -6.8115e-02, -5.3131e-02,  4.2480e-02,  1.3290e-02,\n",
       "          4.0863e-02, -6.3843e-02,  5.2734e-02, -3.8910e-02,  1.0315e-01,\n",
       "         -6.3591e-03,  8.5571e-02,  6.2439e-02,  8.0261e-02, -2.3239e-02,\n",
       "          4.8279e-02, -4.8553e-02,  5.3192e-02,  8.3160e-03, -5.9570e-02,\n",
       "          3.4515e-02,  1.2276e-02,  2.3914e-01, -6.8237e-02, -7.9102e-02,\n",
       "         -4.8157e-02,  3.7048e-02, -7.4402e-02,  6.1218e-02,  6.7078e-02,\n",
       "         -1.4050e-01, -2.3096e-01,  9.6588e-03, -5.7495e-02,  2.2614e-02,\n",
       "         -2.7924e-02, -5.0903e-02,  4.5380e-02, -1.0175e-01,  7.4524e-02,\n",
       "          7.9956e-02,  3.4668e-01, -1.0596e-01, -2.7863e-02, -1.1261e-02,\n",
       "          1.1986e-02, -8.7280e-02,  3.0594e-02,  6.6795e-03,  1.5393e-01,\n",
       "          1.2610e-01, -5.4054e-03, -8.0566e-02, -5.8655e-02,  5.3192e-02,\n",
       "          7.8552e-02, -1.9043e-01,  1.0139e-02, -1.0425e-01,  1.0608e-01,\n",
       "          3.2592e-04, -2.6031e-02,  9.1171e-03,  1.8250e-02, -1.1884e-01,\n",
       "         -1.5961e-02,  2.3230e-01, -9.9670e-02,  5.3314e-02, -7.9224e-02,\n",
       "         -4.5288e-02,  5.5313e-05, -3.9154e-02,  5.2338e-02,  1.1597e-01,\n",
       "         -1.0504e-01,  1.1841e-02, -2.8748e-02, -5.6343e-03,  1.4722e-01,\n",
       "         -3.9948e-02, -1.2781e-01,  7.5073e-02,  5.2948e-02,  1.0150e-01,\n",
       "          5.6152e-02,  8.8135e-02, -3.0014e-02, -9.8572e-02,  2.7618e-02,\n",
       "          4.8866e-03, -9.9548e-02, -2.4853e-03,  3.0502e-02, -3.8910e-02,\n",
       "         -2.3193e-02, -7.1411e-02, -1.7914e-02, -1.9760e-02,  1.7358e-01,\n",
       "         -4.6234e-02,  7.8003e-02,  5.1460e-03,  8.1177e-02,  2.1835e-02,\n",
       "          1.0004e-01,  3.9124e-02,  1.0327e-01, -1.6895e-01, -1.0602e-01,\n",
       "         -2.8381e-02, -7.4036e-02, -1.7958e-03,  9.0332e-02, -5.7281e-02,\n",
       "         -1.5063e-01,  2.9999e-02,  1.9141e-01,  7.5562e-02,  1.1749e-02,\n",
       "         -7.4707e-02, -9.8022e-02, -1.9397e-01, -3.8330e-02, -1.5991e-02,\n",
       "          7.3669e-02, -7.9590e-02,  1.3916e-01,  1.0345e-01, -1.7670e-02,\n",
       "          8.2031e-02,  2.8915e-02,  4.8676e-03,  6.4575e-02, -1.6931e-01,\n",
       "          5.0049e-02, -4.2664e-02, -7.9193e-03,  9.9792e-02, -1.0614e-01,\n",
       "         -1.6449e-02, -6.1920e-02,  3.5400e-02, -5.2490e-02,  3.3627e-03,\n",
       "         -1.1786e-01, -4.1992e-02,  2.0355e-02,  2.3941e-02,  8.3740e-02,\n",
       "          8.9722e-02,  1.6260e-01,  1.6650e-01,  3.2349e-02,  1.0246e-02,\n",
       "          1.3403e-01,  1.1011e-01, -1.6675e-01,  2.1927e-02,  8.8623e-02,\n",
       "          1.5369e-01,  1.1310e-01,  3.8513e-02, -2.3010e-02, -2.4094e-02,\n",
       "         -3.8055e-02, -3.9307e-02,  8.9493e-03, -6.3721e-02,  7.5378e-02,\n",
       "         -1.0048e-02,  1.5915e-02,  1.5820e-01,  1.6711e-01, -1.8347e-01,\n",
       "          4.8859e-02, -1.0529e-01,  6.0394e-02, -2.3596e-01, -7.9346e-03,\n",
       "          1.3260e-02, -1.3037e-01, -1.4366e-02,  1.0156e-01,  7.7209e-02,\n",
       "          2.9037e-02, -9.5276e-02, -2.0943e-03,  1.0675e-01,  7.7637e-02,\n",
       "         -1.0504e-01,  1.3745e-01, -7.0984e-02, -3.8940e-02,  1.1487e-01,\n",
       "         -2.1167e-01, -5.6122e-02,  3.8818e-02, -4.7455e-02, -1.6718e-03,\n",
       "          4.4159e-02,  1.1273e-01, -1.2276e-02,  6.0394e-02, -7.6233e-02,\n",
       "         -1.4856e-01, -1.0461e-01, -3.5400e-02, -3.3051e-02, -4.2999e-02,\n",
       "         -1.0437e-01,  8.1116e-02,  8.6121e-02, -5.7190e-02, -2.8931e-02,\n",
       "         -5.4718e-02, -1.1688e-01,  6.6406e-02, -4.0894e-03, -1.2408e-01,\n",
       "          1.2805e-01,  1.6089e-01,  6.0974e-02, -5.4352e-02, -9.3384e-02,\n",
       "          4.5990e-02, -1.6968e-01,  7.2571e-02,  2.9816e-02,  7.3669e-02,\n",
       "         -1.1238e-02,  2.1530e-02,  6.2744e-02,  7.6294e-02,  5.2338e-02,\n",
       "          3.2684e-02,  2.8152e-02,  9.4910e-02,  1.1185e-02,  2.2522e-02,\n",
       "         -4.8950e-02,  2.5330e-02,  1.1284e-02, -1.0724e-01, -4.8676e-02,\n",
       "          8.0322e-02,  3.9154e-02, -7.6111e-02, -4.1565e-02, -1.3770e-01,\n",
       "         -5.1117e-02, -5.1361e-02, -1.3684e-01, -1.4050e-01,  7.2021e-02,\n",
       "         -1.0699e-01, -2.8290e-02, -9.1782e-03,  2.7539e-01, -1.8298e-01,\n",
       "         -1.2505e-02, -1.0632e-01, -2.7466e-02, -7.4280e-02,  3.6133e-02,\n",
       "         -5.4352e-02,  1.2566e-02, -7.8491e-02, -1.3867e-01,  1.1725e-01,\n",
       "          3.5522e-02,  8.3984e-02,  2.5757e-01, -9.5581e-02,  7.0923e-02,\n",
       "         -7.9529e-02, -1.1499e-01,  1.7151e-02,  1.5918e-01, -1.4490e-01,\n",
       "          4.3579e-02, -4.7852e-02, -5.3925e-02,  1.2103e-01,  2.0435e-01,\n",
       "         -3.1528e-03,  2.0905e-02,  1.6895e-01,  1.7532e-02,  5.1605e-02,\n",
       "          9.2163e-02, -1.2158e-01,  1.4612e-01,  5.0812e-02,  2.4872e-02,\n",
       "          8.1726e-02, -2.4994e-02, -9.0027e-02, -2.7618e-02,  3.1342e-02,\n",
       "          1.3757e-01, -8.1299e-02, -3.2520e-03,  4.3793e-03,  1.0486e-01,\n",
       "         -1.1365e-01, -2.0410e-01, -5.1483e-02, -9.6130e-03, -8.1604e-02,\n",
       "          1.1707e-01,  6.8237e-02], device='cuda:0', dtype=torch.float16),\n",
       " 'activation scores': tensor([ -9.3516, -10.6875,  -7.6055,  ...,  -7.8047,  -7.5430,  -8.5703],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " 'tokens': tensor([ 0.0228,  0.2019, -0.0475,  ...,  0.0483, -0.0155,  0.0285],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<MvBackward0>),\n",
       " 'token scores': tensor([1.6943, 1.6318, 1.6201, 1.6133, 1.5859, 1.5557, 1.5273, 1.5156, 1.4766,\n",
       "         1.4717], device='cuda:0', dtype=torch.float16, grad_fn=<TopkBackward0>),\n",
       " 'token strings': [' stands',\n",
       "  ' splash',\n",
       "  ' со',\n",
       "  ' journal',\n",
       "  ' cette',\n",
       "  ' freel',\n",
       "  ' au',\n",
       "  ' administ',\n",
       "  ' impro',\n",
       "  ' refugee'],\n",
       " 'OV unembed': tensor([ 0.6738,  0.0280, -0.0264,  ..., -0.0505, -0.0039, -0.0689],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<SqueezeBackward1>),\n",
       " 'OV token scores': tensor([1.3613, 1.3105, 1.1953, 1.1182, 1.1143, 1.1035, 1.0889, 1.0752, 1.0713,\n",
       "         1.0596], device='cuda:0', dtype=torch.float16, grad_fn=<TopkBackward0>),\n",
       " 'OV token strings': [' Sear',\n",
       "  ' reference',\n",
       "  ' numerical',\n",
       "  'reference',\n",
       "  ' spiders',\n",
       "  ' Or',\n",
       "  ' Role',\n",
       "  ' master',\n",
       "  ' batch',\n",
       "  ' Background'],\n",
       " 'ln+OV unembed': tensor([-1.7261e-01, -1.0796e-02, -4.4897e-01, -4.2261e-01, -3.5547e-01,\n",
       "         -1.4758e-01,  1.9666e-01, -1.3513e-01,  6.2195e-02, -1.6626e-01,\n",
       "         -6.9580e-01, -9.4116e-02,  2.4805e-01,  4.5532e-01,  5.8777e-02,\n",
       "          4.2456e-01,  4.3701e-01,  1.4929e-01,  3.5449e-01, -1.2366e-01,\n",
       "         -4.1406e-01, -8.6572e-01, -1.4359e-02, -5.2673e-02, -6.4514e-02,\n",
       "         -4.2896e-01,  7.2852e-01,  1.9055e-01,  5.0146e-01, -3.1519e-01,\n",
       "         -1.6052e-01, -7.1899e-02, -9.2896e-02,  1.7285e-01,  3.2983e-01,\n",
       "         -4.8950e-01,  2.6489e-01, -2.2217e-01,  6.9824e-02,  1.3262e+00,\n",
       "         -1.3257e-01, -2.1204e-01,  3.7964e-01, -2.7173e-01,  2.4353e-01,\n",
       "          4.8022e-01,  2.2571e-01, -2.5952e-01, -1.4014e-01,  5.2197e-01,\n",
       "          9.3384e-02,  2.6123e-01,  2.9810e-01,  7.6782e-02,  5.3253e-02,\n",
       "         -2.7295e-01,  5.8447e-01,  4.1870e-02,  2.1594e-01, -9.5825e-02,\n",
       "         -1.1963e-01, -2.8662e-01, -3.0615e-01, -1.3164e+00,  3.0835e-01,\n",
       "         -1.2903e-01,  2.0044e-01,  4.4580e-01, -2.3743e-01, -3.0884e-01,\n",
       "         -2.9834e-01, -3.4058e-01,  5.1025e-01, -8.6121e-02,  3.7817e-01,\n",
       "          5.3857e-01,  1.7737e-01, -5.0684e-01, -6.7969e-01, -6.4600e-01,\n",
       "          2.2449e-01,  2.9480e-02,  2.1924e-01,  3.1348e-01, -6.7261e-02,\n",
       "         -3.9673e-01,  7.3877e-01,  7.6172e-02,  3.3447e-01, -1.4648e-01,\n",
       "         -1.2253e-02, -1.4551e-01,  3.4985e-01,  1.5869e-01,  8.9478e-02,\n",
       "         -2.7344e-01,  2.4451e-01,  7.3425e-02, -3.4424e-02, -6.2256e-01,\n",
       "          1.2720e-01, -4.2407e-01, -1.8457e-01, -1.5051e-01, -2.8198e-01,\n",
       "         -1.8164e-01,  4.3945e-01,  1.1200e-01, -5.1660e-01,  5.6592e-01,\n",
       "          5.8990e-02, -2.4246e-02,  6.9336e-01,  4.5020e-01,  8.8623e-01,\n",
       "          4.2542e-02, -4.1016e-01,  3.1567e-01,  8.6609e-02,  2.6880e-01,\n",
       "          5.2979e-02, -5.8154e-01, -2.3523e-01, -4.1260e-01,  3.9703e-02,\n",
       "         -2.0093e-01,  2.4622e-01, -6.4404e-01,  5.0684e-01,  4.5312e-01,\n",
       "         -8.6121e-02,  2.2131e-01,  3.6407e-02,  3.3594e-01, -3.5736e-02,\n",
       "         -4.2407e-01,  1.4233e-01, -9.5117e-01, -1.8555e-01, -2.2571e-01,\n",
       "          7.8125e-01,  9.1943e-01,  2.7686e-01, -1.4478e-01,  1.0950e-01,\n",
       "         -3.9014e-01, -3.2983e-01,  8.6670e-03, -7.3242e-01,  4.9316e-02,\n",
       "          5.7324e-01,  2.4377e-01, -6.8115e-02, -3.8623e-01, -5.2197e-01,\n",
       "         -4.6112e-02,  5.3613e-01,  2.6514e-01,  5.9784e-02, -3.2764e-01,\n",
       "         -3.0347e-01, -1.1523e-01,  8.5645e-01, -8.9966e-02, -2.1875e-01,\n",
       "         -3.3081e-01,  3.1982e-02,  3.6163e-02, -2.7808e-01, -4.6387e-01,\n",
       "          1.3123e-01,  3.1958e-01,  7.1869e-03, -8.7585e-02,  7.9651e-02,\n",
       "         -3.6914e-01,  1.3574e-01,  7.0923e-02,  2.9053e-01, -7.2607e-01,\n",
       "         -6.4880e-02,  6.8054e-02, -4.5624e-02, -1.7908e-01, -6.4774e-03,\n",
       "         -5.1221e-01, -6.0596e-01,  4.6234e-02, -1.6327e-02,  2.9224e-01,\n",
       "          2.1927e-02,  1.9824e-01,  9.1016e-01,  1.1163e-01,  5.0323e-02,\n",
       "         -9.2697e-03, -4.7485e-01,  5.1562e-01, -2.0966e-02, -1.2408e-01,\n",
       "         -7.7820e-02,  7.0068e-01,  7.2070e-01,  2.6929e-01,  7.8369e-02,\n",
       "          1.7212e-01, -1.4880e-01,  3.1787e-01, -1.0400e+00,  3.6938e-01,\n",
       "         -3.0487e-02,  2.1729e-01,  1.3565e-02,  9.1650e-01, -3.3228e-01,\n",
       "          4.1504e-01,  7.3608e-02,  6.7236e-01,  2.8247e-01,  2.3270e-02,\n",
       "         -4.3579e-01, -6.5771e-01,  1.1157e-01, -2.4719e-01,  2.0557e-01,\n",
       "         -9.2676e-01, -4.4678e-01, -3.7109e-01, -4.4727e-01, -3.4741e-01,\n",
       "         -2.6685e-01, -9.6924e-01,  1.6895e-01, -2.8458e-02, -1.0956e-01,\n",
       "          2.5366e-01,  7.5439e-02,  1.3501e-01,  1.3062e-01, -4.5850e-01,\n",
       "          1.1221e+00,  2.7490e-01, -2.7237e-02, -6.8426e-05,  9.0881e-02,\n",
       "          4.2090e-01,  3.1281e-02, -4.0332e-01, -2.5073e-01, -1.3647e-01,\n",
       "         -1.4087e-01,  6.5186e-01, -2.7295e-01, -1.1973e+00, -1.5717e-03,\n",
       "         -1.4539e-01,  3.8743e-06, -1.4038e-01,  1.4542e-02,  9.2163e-03,\n",
       "          3.1323e-01,  3.5858e-02, -2.2571e-01, -1.3123e-01, -1.3477e-01,\n",
       "          3.1421e-01,  7.5342e-01, -4.1016e-01,  2.5635e-01, -9.0527e-01,\n",
       "          4.1724e-01,  5.1709e-01, -2.6050e-01,  1.8347e-01, -2.6318e-01,\n",
       "         -5.7520e-01,  3.2349e-02, -4.7046e-01, -4.4336e-01, -1.7529e-01,\n",
       "         -1.2295e+00,  2.2083e-01,  6.0205e-01,  4.4507e-01, -6.4026e-02,\n",
       "          9.9463e-01, -2.3511e-01, -5.2051e-01, -8.5388e-02, -2.0471e-01,\n",
       "          2.2095e-01, -2.3853e-01,  2.6660e-01, -1.9727e-01,  5.3564e-01,\n",
       "         -1.5186e-01, -1.5295e-01, -2.5220e-01, -2.9175e-01,  4.3408e-01,\n",
       "         -1.0291e-01, -3.8818e-01,  4.3530e-01, -5.0342e-01, -3.8452e-01,\n",
       "         -1.2842e-01, -6.3574e-01,  1.6736e-01,  4.6997e-01,  1.0162e-01,\n",
       "          3.8110e-01, -1.3745e-01, -4.5258e-02,  9.0149e-02,  2.2546e-01,\n",
       "          5.0830e-01,  1.6983e-02,  3.3252e-01, -4.4604e-01,  1.0645e+00,\n",
       "          2.7100e-01,  7.9297e-01, -3.6450e-01,  4.1284e-01,  5.0439e-01,\n",
       "          3.9282e-01, -3.4570e-01,  8.8721e-01, -8.9233e-02, -2.2449e-01,\n",
       "          4.1357e-01, -2.0923e-01,  1.4124e-01,  6.5869e-01, -8.5815e-02,\n",
       "          3.0493e-01,  3.2007e-01,  3.1586e-02,  7.3047e-01, -9.6533e-01,\n",
       "         -1.6711e-01, -3.2373e-01, -9.1064e-02, -5.2783e-01, -1.6272e-01,\n",
       "          8.7952e-02,  8.9417e-02, -4.3018e-01, -2.2754e-01, -7.0947e-01,\n",
       "          2.6953e-01, -2.8809e-01,  3.1006e-01,  3.6938e-01, -2.3865e-02,\n",
       "         -4.4580e-01,  1.4844e-01,  5.0488e-01,  6.1719e-01,  1.8542e-01,\n",
       "         -2.0752e-01,  1.2048e-01, -1.0586e+00,  5.3516e-01, -7.6758e-01,\n",
       "         -1.7664e-01,  2.6782e-01,  3.5742e-01, -2.9077e-01,  3.5669e-01,\n",
       "          2.3926e-01, -3.4351e-01,  6.2305e-01,  8.3252e-01, -3.6108e-01,\n",
       "         -5.1300e-02, -1.8945e-01,  6.5625e-01,  8.6914e-02, -2.0276e-01,\n",
       "         -6.2158e-01,  4.7226e-03, -2.0520e-01,  5.0244e-01, -3.9816e-04,\n",
       "         -5.0928e-01, -5.4785e-01,  4.6069e-01,  8.3557e-02, -3.7915e-01,\n",
       "         -6.6589e-02,  6.2158e-01, -4.1431e-01,  4.8798e-02, -4.1699e-01,\n",
       "         -2.2415e-02,  7.1045e-01, -5.1025e-01, -3.5522e-02,  9.1858e-02,\n",
       "          3.7323e-02,  6.9531e-01,  4.2542e-02,  2.6794e-02, -1.0529e-01,\n",
       "         -6.9287e-01, -2.1350e-01,  5.2051e-01, -3.3984e-01,  8.2092e-02,\n",
       "         -1.7334e-01,  4.8657e-01,  5.1367e-01, -5.3809e-01, -7.7698e-02,\n",
       "         -2.4475e-01,  2.5635e-01,  1.7322e-01, -3.3667e-01,  1.7407e-01,\n",
       "          3.4790e-02, -3.0737e-01,  3.8738e-03, -7.0898e-01, -1.8933e-01,\n",
       "         -2.9199e-01,  2.7368e-01,  1.0608e-01, -5.8594e-01, -2.4146e-01,\n",
       "          4.6558e-01, -6.3232e-02,  6.8848e-01, -3.8745e-01,  3.9941e-01,\n",
       "         -2.5781e-01, -3.1055e-01,  4.6460e-01, -3.1494e-01, -7.2949e-01,\n",
       "         -1.3843e-01,  9.6924e-02,  2.2961e-01, -1.4209e-01,  1.5039e-01,\n",
       "         -2.5244e-01, -1.1877e-01,  2.1399e-01, -7.1533e-01,  2.9370e-01,\n",
       "          5.7755e-03, -1.6248e-01, -3.7354e-01,  5.0684e-01, -2.6074e-01,\n",
       "          1.7969e-01,  2.3938e-01, -1.6113e-01,  2.8076e-01, -8.0017e-02,\n",
       "          2.6489e-01, -1.9531e-01, -1.7432e-01, -9.3994e-01,  6.8945e-01,\n",
       "          1.2201e-01,  1.5051e-01, -7.2144e-02, -5.1660e-01, -2.6099e-01,\n",
       "          8.2861e-01, -5.9863e-01, -3.8062e-01,  3.7354e-01,  1.1273e-01,\n",
       "         -1.6321e-01,  2.5806e-01,  1.2524e-01,  8.6914e-01,  3.4741e-01,\n",
       "         -6.8701e-01,  1.4612e-01,  2.4561e-01,  3.5736e-02,  3.8794e-01,\n",
       "         -2.1533e-01,  4.3530e-01,  3.8269e-02, -1.8481e-01,  2.7808e-01,\n",
       "         -3.1714e-01, -1.4722e-01,  4.1211e-01, -4.5703e-01, -2.8223e-01,\n",
       "          7.0605e-01,  1.6391e-05, -5.2032e-02, -1.4185e-01, -5.5859e-01,\n",
       "          6.9385e-01,  8.2373e-01,  1.0931e-01, -2.7023e-02, -3.6407e-02,\n",
       "         -4.3799e-01,  3.6621e-01, -7.8906e-01, -5.3772e-02, -7.3975e-01,\n",
       "         -4.0588e-02,  2.3291e-01], device='cuda:0', dtype=torch.float16),\n",
       " 'ln+OV token scores': tensor([1.3262, 1.1221, 1.0645, 0.9946, 0.9194, 0.9165, 0.9102, 0.8872, 0.8862,\n",
       "         0.8691], device='cuda:0', dtype=torch.float16),\n",
       " 'ln+OV token strings': ['E',\n",
       "  '�',\n",
       "  'ation',\n",
       "  'as',\n",
       "  '�',\n",
       "  '�',\n",
       "  '\\x0e',\n",
       "  ' that',\n",
       "  '�',\n",
       "  'iz'],\n",
       " 'QK unembed': tensor([ 0.4292,  0.2150, -0.0509,  ...,  0.0249, -0.1013,  0.0155],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<SqueezeBackward1>),\n",
       " 'QK token scores': tensor([1.5762, 1.4863, 1.4678, 1.4658, 1.4580, 1.4443, 1.4443, 1.4277, 1.4229,\n",
       "         1.4141], device='cuda:0', dtype=torch.float16, grad_fn=<TopkBackward0>),\n",
       " 'QK token strings': [' early',\n",
       "  ' preceded',\n",
       "  ' alive',\n",
       "  ' cra',\n",
       "  ' fel',\n",
       "  'aming',\n",
       "  ' faint',\n",
       "  ' affirmative',\n",
       "  ' fasting',\n",
       "  ' simultaneous']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat at L1 (this multiplies by the wrong features, but I'm just seeing what breaks)\n",
    "\n",
    "analyze_linearized_feature(\n",
    "    feature_idx=100,\n",
    "    sample_idx=30,\n",
    "    token_idx=30,\n",
    "    model=model,\n",
    "    layer=1,\n",
    "    data=data,\n",
    "    encoder=sae_l1,\n",
    "    batch_size=32,\n",
    "    n_tokens=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Changing model dtype to torch.float16\n",
      "Model device: cuda:0\n",
      "Tokens shape: torch.Size([215402, 128]), dtype: torch.int64, device: cuda:0\n",
      "{'batch_size': 4096,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.99,\n",
      " 'buffer_batches': 12288,\n",
      " 'buffer_mult': 384,\n",
      " 'buffer_size': 1572864,\n",
      " 'd_mlp': 2048,\n",
      " 'dict_mult': 8,\n",
      " 'enc_dtype': 'fp32',\n",
      " 'l1_coeff': 0.0003,\n",
      " 'lr': 0.0001,\n",
      " 'model_batch_size': 512,\n",
      " 'num_tokens': 2000000000,\n",
      " 'seed': 52,\n",
      " 'seq_len': 128}\n",
      "Encoder device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(HookedTransformer(\n",
       "   (embed): Embed()\n",
       "   (hook_embed): HookPoint()\n",
       "   (pos_embed): PosEmbed()\n",
       "   (hook_pos_embed): HookPoint()\n",
       "   (blocks): ModuleList(\n",
       "     (0-1): 2 x TransformerBlock(\n",
       "       (ln1): LayerNormPre(\n",
       "         (hook_scale): HookPoint()\n",
       "         (hook_normalized): HookPoint()\n",
       "       )\n",
       "       (ln2): LayerNormPre(\n",
       "         (hook_scale): HookPoint()\n",
       "         (hook_normalized): HookPoint()\n",
       "       )\n",
       "       (attn): Attention(\n",
       "         (hook_k): HookPoint()\n",
       "         (hook_q): HookPoint()\n",
       "         (hook_v): HookPoint()\n",
       "         (hook_z): HookPoint()\n",
       "         (hook_attn_scores): HookPoint()\n",
       "         (hook_pattern): HookPoint()\n",
       "         (hook_result): HookPoint()\n",
       "       )\n",
       "       (mlp): MLP(\n",
       "         (hook_pre): HookPoint()\n",
       "         (hook_post): HookPoint()\n",
       "       )\n",
       "       (hook_attn_in): HookPoint()\n",
       "       (hook_q_input): HookPoint()\n",
       "       (hook_k_input): HookPoint()\n",
       "       (hook_v_input): HookPoint()\n",
       "       (hook_mlp_in): HookPoint()\n",
       "       (hook_attn_out): HookPoint()\n",
       "       (hook_mlp_out): HookPoint()\n",
       "       (hook_resid_pre): HookPoint()\n",
       "       (hook_resid_mid): HookPoint()\n",
       "       (hook_resid_post): HookPoint()\n",
       "     )\n",
       "   )\n",
       "   (ln_final): LayerNormPre(\n",
       "     (hook_scale): HookPoint()\n",
       "     (hook_normalized): HookPoint()\n",
       "   )\n",
       "   (unembed): Unembed()\n",
       " ),\n",
       " tensor([[    1,    10, 27498,  ...,    65, 32489,   426],\n",
       "         [    1, 14101, 27849,  ...,   282,  2374,   327],\n",
       "         [    1,  1358,   684,  ...,    10,  1320,    14],\n",
       "         ...,\n",
       "         [    1,  5613,   426,  ...,  1358,  7167,    65],\n",
       "         [    1,  4552,   324,  ...,  3270,  2012,    62],\n",
       "         [    1, 42978, 23925,  ...,  5181,    65,  3313]], device='cuda:0'),\n",
       " AutoEncoder())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_all(model_name=\"gelu-2l\", run=\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
